{
    "id": "4a1de5495527e35c3bfdcd53152167e93a360bdb88603b202e6257b1f588edc0",
    "title": "A Google Gemini model now has a “dial” to adjust how much it reasons",
    "link": "https://www.technologyreview.com/2025/04/17/1115375/a-google-gemini-model-now-has-a-dial-to-adjust-how-much-it-reasons/",
    "published_iso": "2025-04-17T19:00:00Z",
    "summary": "<p>Google DeepMind’s latest update to a top Gemini AI model includes a dial to control how much the system “thinks” through a response. The new feature is ostensibly designed to save money for developers, but it also concedes a problem: Reasoning models, the tech world’s new obsession, are prone to overthinking, burning money and energy in the process.</p>\n\n\n\n<p>Since 2019, there have been a couple of tried and true ways to make an AI model more powerful. One was to make it bigger by using more training data, and the other was to give it better feedback on what constitutes a good answer. But toward the end of last year, Google DeepMind and other AI companies turned to a third method: reasoning.</p>\n\n\n\n<p>“We’ve been really pushing on ‘thinking,’” says Jack Rae, a principal research scientist at DeepMind. Such models, which are built to work through problems logically and spend more time arriving at an answer, rose to prominence earlier this year with the launch of the DeepSeek R1 model. They’re attractive to AI companies because they can make an existing model better by training it to approach a problem pragmatically. That way, the companies can avoid having to build a new model from scratch.&nbsp;</p>\n\n\n\n<p>When the AI model dedicates more time (and <a href=\"https://www.technologyreview.com/2025/01/31/1110776/deepseek-might-not-be-such-good-news-for-energy-after-all/\">energy</a>) to a query, it costs more to run. <a href=\"https://arcprize.org/leaderboard\">Leaderboards</a> of reasoning models show that one task can cost upwards of $200 to complete. The promise is that this extra time and money help reasoning models do better at handling challenging tasks, like analyzing code or gathering information from lots of documents.&nbsp;</p>\n\n\n\n<p>“The more you can iterate over certain hypotheses and thoughts,” says Google DeepMind chief technical officer Koray Kavukcuoglu, the more “it’s going to find the right thing.”</p>\n\n\n\n<p>This isn’t true in all cases, though. “The model overthinks,” says Tulsee Doshi, who leads the product team at Gemini, referring specifically to Gemini Flash 2.5, the model released today that includes a slider for developers to dial back how much it thinks. “For simple prompts, the model does think more than it needs to.”&nbsp;</p>\n\n\n\n<p>When a model spends longer than necessary on a problem, it makes the model expensive to run for developers and worsens AI’s <a href=\"https://www.technologyreview.com/2024/12/13/1108719/ais-emissions-are-about-to-skyrocket-even-further/\">environmental footprint</a>.</p>\n\n\n\n<p>Nathan Habib, an engineer at Hugging Face who has studied the proliferation of such reasoning models, says overthinking is abundant. In the rush to show off smarter AI, companies are reaching for reasoning models like hammers even where there’s no nail in sight, Habib says. Indeed, when OpenAI <a href=\"https://www.technologyreview.com/2025/02/27/1112619/openai-just-released-gpt-4-5-and-says-it-is-its-biggest-and-best-chat-model-yet/amp/\">announced</a> a new model in February, it said it would be the company’s last nonreasoning model.&nbsp;</p>\n\n\n\n<p>The performance gain is “undeniable” for certain tasks, Habib says, but not for many others where people normally use AI. Even when reasoning is used for the right problem, things can go awry. Habib showed me an example of a leading reasoning model that was asked to work through an organic chemistry problem. It started out okay, but halfway through its reasoning process the model’s responses started resembling a meltdown: It sputtered “Wait, but …” hundreds of times. It ended up taking far longer than a nonreasoning model would spend on one task. Kate Olszewska, who works on evaluating Gemini models at DeepMind, says Google’s models can also get stuck in loops.</p>\n\n\n\n<p>Google’s new “reasoning” dial is one attempt to solve that problem. For now, it’s built not for the consumer version of Gemini but for developers who are making apps. Developers can set a budget for how much computing power the model should spend on a certain problem, the idea being to turn down the dial if the task shouldn’t involve much reasoning at all. Outputs from the model are about six times more expensive to generate when reasoning is turned on.</p>\n\n\n\n<p>Another reason for this flexibility is that it’s not yet clear when more reasoning will be required to get a better answer.</p>\n\n\n\n<p>“It’s really hard to draw a boundary on, like, what’s the perfect task right now for thinking?” Rae says.&nbsp;</p>\n\n\n\n<p>Obvious tasks include coding (developers might paste hundreds of lines of code into the model and then ask for help), or generating expert-level research reports. The dial would be turned way up for these, and developers might find the expense worth it. But more testing and feedback from developers will be needed to find out when medium or low settings are good enough.</p>\n\n\n\n<p>Habib says the amount of investment in reasoning models is a sign that the old paradigm for how to make models better is changing. “Scaling laws are being replaced,” he says.&nbsp;</p>\n\n\n\n\n\n<p>Instead, companies are betting that the best responses will come from longer thinking times rather than bigger models. It’s been clear for several years that AI companies are spending more money on inferencing—when models are actually “pinged” to generate an answer for something—than on training, and this spending will <a href=\"https://www.technologyreview.com/2025/01/31/1110776/deepseek-might-not-be-such-good-news-for-energy-after-all/\">accelerate</a> as reasoning models take off. Inferencing is also responsible for a growing share of emissions.</p>\n\n\n\n<p>(While on the subject of models that “reason” or “think”: an AI model cannot perform these acts in the way we normally use such words when talking about humans. I asked Rae why the company uses anthropomorphic language like this. “It’s allowed us to have a simple name,” he says, “and people have an intuitive sense of what it should mean.” Kavukcuoglu says that Google is not trying to mimic any particular human cognitive process in its models.)</p>\n\n\n\n<p>Even if reasoning models continue to dominate, Google DeepMind isn’t the only game in town. When the results from DeepSeek began circulating in December and January, it triggered a nearly $1 trillion dip in the stock market because it promised that powerful reasoning models could be had for cheap. The model is referred to as “open weight”—in other words, its internal settings, called weights, are made publicly available, allowing developers to run it on their own rather than paying to access proprietary models from Google or OpenAI. (The term “open source” is reserved for models that disclose the data they were trained on.)&nbsp;</p>\n\n\n\n<p>So why use proprietary models from Google when open ones like DeepSeek are performing so well? Kavukcuoglu says that coding, math, and finance are cases where “there’s high expectation from the model to be very accurate, to be very precise, and to be able to understand really complex situations,” and he expects models that deliver on that, open or not, to win out. In DeepMind’s view, this reasoning will be the foundation of future AI models that act on your behalf and solve problems for you.</p>\n\n\n\n<p>“Reasoning is the key capability that builds up intelligence,” he says. “The moment the model starts thinking, the agency of the model has started.”</p>\n\n\n\n<p><em>This story was updated to clarify the problem of &#8220;overthinking.</em>&#8220;</p>",
    "source_feed": "https://www.technologyreview.com/topic/artificial-intelligence/feed/",
    "scraped_at_iso": "2025-05-03T00:24:49Z",
    "filter_verdict": {
        "importance_level": "Interesting",
        "topic": "AI Models",
        "reasoning_summary": "The article reports a verifiable update to Google's Gemini AI model with a new feature to control reasoning depth, presenting a novel approach to optimizing AI performance and cost. This is a factual development with potential implications for AI model efficiency.",
        "primary_topic_keyword": "AI reasoning control"
    },
    "filter_error": null,
    "filtered_at_iso": "2025-05-03T00:28:40Z",
    "topic": "AI Models",
    "is_breaking": false,
    "primary_keyword": "AI reasoning control",
    "similarity_check_error": null,
    "selected_image_url": "https://wp.technologyreview.com/wp-content/uploads/2025/04/thought-dial2a.jpg?resize=1200,600",
    "seo_agent_results": {
        "generated_title_tag": "Google Gemini Adds AI Reasoning Control Dial for Developers",
        "generated_meta_description": "Google DeepMind introduces an AI reasoning control dial for Gemini models, allowing developers to adjust computational effort and costs.",
        "generated_json_ld": "<script type=\"application/ld+json\">  \n{  \n  \"@context\": \"https://schema.org\",  \n  \"@type\": \"NewsArticle\",  \n  \"headline\": \"Google Gemini Adds AI Reasoning Control Dial for Developers\",  \n  \"description\": \"Google DeepMind introduces an AI reasoning control dial for Gemini models, allowing developers to adjust computational effort and costs.\",  \n  \"keywords\": [\"AI reasoning control\"],  \n  \"mainEntityOfPage\": { \"@type\": \"WebPage\", \"@id\": \"https://www.technologyreview.com/2025/04/17/1115375/a-google-gemini-model-now-has-a-dial-to-adjust-how-much-it-reasons/\" },  \n  \"image\": { \"@type\": \"ImageObject\", \"url\": \"https://wp.technologyreview.com/wp-content/uploads/2025/04/thought-dial2a.jpg?resize=1200,600\" },  \n  \"datePublished\": \"2025-04-17T19:00:00Z\",  \n  \"author\": { \"@type\": \"Person\", \"name\": \"AI News Team\" },  \n  \"publisher\": {  \n    \"@type\": \"Organization\",  \n    \"name\": \"Dacoola\",  \n    \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://i.imgur.com/A5Wdp6f.png\" }  \n  }  \n}  \n</script>",
        "generated_article_body_md": "## A Google Gemini Model Now Has a “Dial” to Adjust How Much It Reasons  \n\nGoogle DeepMind has introduced a new feature for its Gemini AI models: a dial that lets developers control how much the system \"thinks\" before generating a response. This **AI reasoning control** mechanism aims to optimize costs and energy usage, addressing a growing issue in AI development—overthinking. Reasoning models, which analyze problems more deeply before answering, have become popular for improving performance but often consume excessive resources on simple tasks.  \n\nThe reasoning dial, currently available in Gemini Flash 2.5, allows developers to adjust computational effort based on task complexity. For straightforward queries, reducing reasoning time can cut costs significantly—outputs are six times more expensive when reasoning is fully engaged. Google acknowledges that models like Gemini Flash 2.5 sometimes \"overthink,\" wasting energy and inflating operational expenses unnecessarily. Nathan Habib, an engineer at Hugging Face, notes that while reasoning models excel in tasks like coding and research, they frequently overcomplicate simpler requests.  \n\n### Balancing Performance and Efficiency  \nGoogle’s solution offers flexibility, letting developers prioritize efficiency for basic tasks while reserving deeper reasoning for complex challenges like code analysis or document synthesis. However, determining the optimal reasoning level remains an open question. Jack Rae, a principal research scientist at DeepMind, admits that defining the \"perfect task\" for reasoning is difficult. Meanwhile, the AI industry is shifting focus from simply scaling model size to refining reasoning capabilities, signaling a broader trend toward smarter, more adaptable AI systems."
    },
    "seo_agent_error": null,
    "generated_tags": [
        "Google Gemini",
        "AI reasoning control",
        "Gemini Flash 2.5",
        "AI efficiency",
        "computational cost optimization",
        "DeepMind",
        "AI model performance",
        "AI overthinking",
        "adaptive AI systems",
        "AI industry trends"
    ],
    "tags_agent_error": null,
    "trend_score": 10.0,
    "slug": "a-google-gemini-model-now-has-a-dial-to-adjust-how-much-it-reasons",
    "audio_url": null,
    "post_template_hash": "c3831ae59bdf615c6cf491b278dcca53d254b448a7420510b50d004bb9072292"
}