{
    "id": "e1e0227807af9d695fdf8111efdce2908fedf7ae7fd7ae096263abac99faf256",
    "title": "NVIDIA Research at ICLR — Pioneering the Next Wave of Multimodal Generative AI",
    "link": "https://blogs.nvidia.com/blog/ai-research-iclr-2025/",
    "published_iso": "2025-04-24T13:00:48Z",
    "summary": "<div id=\"bsf_rt_marker\"></div><p>Advancing AI requires a full-stack approach, with a powerful foundation of computing infrastructure — including accelerated processors and networking technologies — connected to optimized compilers, algorithms and applications.</p>\n<p><a href=\"https://www.nvidia.com/en-us/research/\" target=\"_blank\">NVIDIA Research</a> is innovating across this spectrum, supporting virtually every industry in the process. At this week’s <a href=\"https://iclr.cc/\" target=\"_blank\">International Conference on Learning Representations</a> (ICLR), taking place April 24-28 in Singapore, more than 70 NVIDIA-authored papers introduce AI developments with applications in autonomous vehicles, healthcare, multimodal content creation, robotics and more.</p>\n<p>“ICLR is one of the world’s most impactful AI conferences, where researchers introduce important technical innovations that move every industry forward,” said Bryan Catanzaro, vice president of applied deep learning research at NVIDIA. “The research we’re contributing this year aims to accelerate every level of the computing stack to amplify the impact and utility of AI across industries.”</p>\n<p></p>\n<h2><b>Research That Tackles Real-World Challenges</b></h2>\n<p>Several <a href=\"https://research.nvidia.com/publications?f%5B0%5D=publication_events%3A38\" target=\"_blank\">NVIDIA-authored papers at ICLR</a> cover groundbreaking work in multimodal generative AI and novel methods for AI training and synthetic data generation, including: <b></b></p>\n<ul>\n<li><a href=\"https://blogs.nvidia.com/blog/fugatto-gen-ai-sound-model/\"><b>Fugatto</b></a>: The world’s most flexible audio generative AI model, Fugatto generates or transforms any mix of music, voices and sounds described with prompts using any combination of text and audio files. Other NVIDIA models at ICLR improve audio large language models (<a href=\"https://www.nvidia.com/en-us/glossary/large-language-models/\" target=\"_blank\">LLMs</a>) to better understand speech.</li>\n<li><a href=\"https://hamster-robot.github.io/\" target=\"_blank\"><b>HAMSTER</b></a>: This paper demonstrates that a hierarchical design for vision-language-action models can improve their ability to transfer knowledge from off-domain fine-tuning data — inexpensive data that doesn’t need to be collected on actual robot hardware — to improve a robot’s skills in testing scenarios. <b>  </b></li>\n<li><a href=\"https://developer.nvidia.com/blog/hymba-hybrid-head-architecture-boosts-small-language-model-performance/\" target=\"_blank\"><b>Hymba</b></a>: This family of small language models uses a hybrid model architecture to create LLMs that blend the benefits of transformer models and state space models, enabling high-resolution recall, efficient context summarization and common-sense reasoning tasks. With its hybrid approach, Hymba improves throughput by 3x and reduces cache by almost 4x without sacrificing performance.</li>\n<li><a href=\"https://hanlab.mit.edu/projects/longvila\" target=\"_blank\"><b>LongVILA</b></a>: This training pipeline enables efficient visual language model training and inference for long video understanding. Training AI models on long videos is compute and memory-intensive — so this paper introduces a system that efficiently parallelizes long video training and inference, with training scalability up to 2 million tokens on 256 GPUs. LongVILA achieves state-of-the-art performance across nine popular video benchmarks.</li>\n<li><a href=\"https://openreview.net/forum?id=AyC4uxx2HW\" target=\"_blank\"><b>LLaMaFlex</b></a>: This paper introduces a new zero-shot generation technique to create a family of compressed LLMs based on one large model. The researchers found that LLaMaFlex can generate compressed models that are as accurate or better than state-of-the art pruned, flexible and trained-from-scratch models — a capability that could be applied to significantly reduce the cost of training model families compared to techniques like pruning and knowledge distillation.</li>\n<li><a href=\"https://research.nvidia.com/labs/genair/proteina/\" target=\"_blank\"><b>Proteina</b></a>: This model can generate diverse and designable protein backbones, the framework that holds a protein together. It uses a <a href=\"https://blogs.nvidia.com/blog/what-is-a-transformer-model/\">transformer model architecture</a> with up to 5x as many parameters as previous models.</li>\n<li><a href=\"https://arxiv.org/abs/2503.04538\" target=\"_blank\"><b>SRSA</b></a>: This framework addresses the challenge of teaching robots new tasks using a preexisting skill library — so instead of learning from scratch, a robot can apply and adapt its existing skills to the new task. By developing a framework to predict which preexisting skill would be most relevant to a new task, the researchers were able to improve zero-shot success rates on unseen tasks by 19%.</li>\n<li><a href=\"https://jiawei-yang.github.io/STORM/\" target=\"_blank\"><b>STORM</b></a>: This model can reconstruct dynamic outdoor scenes — like cars driving or trees swaying in the wind — with a precise 3D representation inferred from just a few snapshots. The model, which can reconstruct large-scale outdoor scenes in 200 milliseconds, has potential applications in autonomous vehicle development.</li>\n</ul>\n<p><i>Discover the </i><a href=\"https://research.nvidia.com/publications\" target=\"_blank\"><i>latest work</i></a><i> from </i><a href=\"https://www.nvidia.com/en-us/research/\" target=\"_blank\"><i>NVIDIA Research</i></a><i>, a global team of around 400 experts in fields including computer architecture, generative AI, graphics, self-driving cars and robotics. </i></p>",
    "source_feed": "https://blogs.nvidia.com/feed/",
    "scraped_at_iso": "2025-05-03T01:30:11Z",
    "filter_verdict": {
        "importance_level": "Interesting",
        "topic": "Research",
        "reasoning_summary": "NVIDIA Research presenting over 70 papers at ICLR, a major AI conference, with applications across multiple industries, indicating significant but not urgent developments.",
        "primary_topic_keyword": "NVIDIA AI research"
    },
    "filter_error": null,
    "filtered_at_iso": "2025-05-03T01:35:34Z",
    "topic": "Research",
    "is_breaking": false,
    "primary_keyword": "NVIDIA AI research",
    "similarity_check_error": null,
    "selected_image_url": "https://blogs.nvidia.com/wp-content/uploads/2025/04/ICLR_featuredstill.jpg",
    "seo_agent_results": {
        "generated_title_tag": "NVIDIA AI Research Showcases Multimodal Generative AI at ICLR",
        "generated_meta_description": "NVIDIA AI research highlights 70+ papers at ICLR 2025, advancing multimodal generative AI, robotics, and synthetic data generation.",
        "generated_json_ld": "<script type=\"application/ld+json\">  \n{  \n  \"@context\": \"https://schema.org\",  \n  \"@type\": \"NewsArticle\",  \n  \"headline\": \"NVIDIA AI Research Showcases Multimodal Generative AI at ICLR\",  \n  \"description\": \"NVIDIA AI research highlights 70+ papers at ICLR 2025, advancing multimodal generative AI, robotics, and synthetic data generation.\",  \n  \"keywords\": [\"NVIDIA AI research\"],  \n  \"mainEntityOfPage\": { \"@type\": \"WebPage\", \"@id\": \"https://blogs.nvidia.com/blog/ai-research-iclr-2025/\" },  \n  \"image\": { \"@type\": \"ImageObject\", \"url\": \"https://blogs.nvidia.com/wp-content/uploads/2025/04/ICLR_featuredstill.jpg\" },  \n  \"datePublished\": \"2025-04-24T13:00:48Z\",  \n  \"author\": { \"@type\": \"Person\", \"name\": \"AI News Team\" },  \n  \"publisher\": {  \n    \"@type\": \"Organization\",  \n    \"name\": \"Dacoola\",  \n    \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://i.imgur.com/A5Wdp6f.png\" }  \n  }  \n}  \n</script>",
        "generated_article_body_md": "## NVIDIA Research at ICLR — Pioneering the Next Wave of Multimodal Generative AI  \n\nNVIDIA Research is pushing the boundaries of AI with a full-stack approach, combining accelerated computing, optimized algorithms, and real-world applications. At the International Conference on Learning Representations (ICLR) 2025 in Singapore, NVIDIA presented over 70 papers spanning autonomous vehicles, healthcare, robotics, and multimodal content creation. Bryan Catanzaro, VP of applied deep learning research at NVIDIA, emphasized the conference’s role in driving industry-wide AI advancements.  \n\nAmong the standout innovations is **Fugatto**, the world’s most flexible audio generative AI model, capable of transforming or generating music, voices, and sounds using text or audio prompts. Another breakthrough, **HAMSTER**, improves robot learning by leveraging off-domain data, while **Hymba** enhances small language models with a hybrid architecture, boosting throughput by 3x. **LongVILA** tackles long-video understanding with scalable training, achieving top performance across nine benchmarks.  \n\n### Real-World AI Applications  \nNVIDIA’s research also includes **LLaMaFlex**, a zero-shot technique for generating compressed LLMs, and **Proteina**, a transformer-based model for designing protein backbones. In robotics, **SRSA** improves task adaptation by predicting relevant preexisting skills, increasing zero-shot success rates by 19%. Meanwhile, **STORM** reconstructs dynamic outdoor scenes in milliseconds, aiding autonomous vehicle development. These advancements underscore NVIDIA’s commitment to solving complex challenges across industries."
    },
    "seo_agent_error": null,
    "generated_tags": [
        "NVIDIA Research",
        "Multimodal Generative AI",
        "ICLR 2025",
        "Fugatto AI",
        "HAMSTER Robotics",
        "Hymba Language Model",
        "LongVILA Video Understanding",
        "LLaMaFlex LLM Compression",
        "Proteina Protein Design",
        "STORM Scene Reconstruction"
    ],
    "tags_agent_error": null,
    "trend_score": 10.0,
    "slug": "nvidia-research-at-iclr-pioneering-the-next-wave-of-multimodal-generative-ai",
    "audio_url": null
}