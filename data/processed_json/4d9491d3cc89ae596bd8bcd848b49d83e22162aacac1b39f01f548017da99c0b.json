{
    "id": "4d9491d3cc89ae596bd8bcd848b49d83e22162aacac1b39f01f548017da99c0b",
    "title": "To Speed up AI, Just Outsource Memory",
    "link": "https://spectrum.ieee.org/computer-memory-ai",
    "published_iso": "2025-05-06T15:00:05Z",
    "summary": "<img src=\"https://spectrum.ieee.org/media-library/conceptual-illustration-of-a-data-server-storage-room-at-the-center-of-the-image-the-servers-and-floor-begin-to-fade-into-blac.jpg?id=60038882&width=1200&height=600&coordinates=0%2C1026%2C0%2C1026\" /><br /><br /><p>Modern society is becoming increasing data hungry, especially as the use of AI <a href=\"https://spectrum.ieee.org/ai-index-2025\" target=\"_blank\">continues to grow exponentially</a>. As a result, ensuring enough computer memory—and power to sustainable support that memory—has become a major concern. </p><p>Now, the software company <a href=\"https://kove.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Kove</a> has figured out a way to pool and dynamically outsource computer memory in a way that dramatically boosts computer memory efficiency. Kove’s system leverages external pooled memory to produce results even faster than can be achieved with local memory.</p><p>For one of Kove’s clients, the approach reduced the power consumption of servers by up to 54 percent. For another, it slashed the time needed to run a complex AI model, enabling a 60-day training run to be completed in just one day. </p><p>John Overton, the CEO of Kove, has been working on this software solution for 15 years. He emphasizes that meeting the high demand for memory is one of the most pressing concerns facing the computer industry. <span>“You hear of people running out of memory all the time,” he says, noting the AI and machine learning algorithms require huge amounts of data.</span><strong></strong></p><p>Yet computers can only crunch the data as fast as their memory allows, and will crash mid-task without enough of it. Kove’s software-defined memory (SDM) solution aims to mitigate this problem by outsourcing memory needs to external servers.</p><h2>How Software-defined Memory Works</h2><p>Overton notes that many computer scientists thought that outsourcing memory—at least with the same efficiency as processing the data locally—was impossible. Such a feat would defy the laws of physics. </p><p>The issue comes down to the fact that electrons can only travel at the speed of light. Therefore, if an external server is 150 meters away from a mainframe computer, there would inevitably be a delay of ~500 nanoseconds in the electrons reaching the external server: roughly 3.3 nanoseconds of latency (delay) for each meter the data must travel. “People have presumed this problem is unsolvable,” says Overton. <strong></strong></p><p>SDM is able to overcome this issue and utilize pooled memory at super fast speeds because of the way it strategically divides up the data being processed. It ensures the data that would be most efficiently processed locally stays with the CPU, while the other data resides in the external memory pool. While this doesn’t actually transmit data faster than the speed of light, it is more efficient than processing all the data locally using a CPU. In this way, SDM can actually process data faster than it would if the data was kept locally.</p><p>“We’re clever about making sure that the processor gets the memory that it needs from the local motherboard,” Overton explains. “And the results are spectacular.” <span>As an example, he notes that one of his clients, </span><a href=\"https://www.redhat.com/\" target=\"_blank\">RedHat</a><span>, experienced a 9 percent reduction in latency using SDM.</span></p><h2>Energy Savings from Pooled Memory</h2><p>Another key advantage with the SDM approach is a slash in <a href=\"https://spectrum.ieee.org/nuclear-powered-data-center\" target=\"_blank\">energy needs</a>. Typically, scientists need to run models on whatever server they have available, and often need to run medium sized models on large servers to accommodate temporary spikes in memory needs. This means running larger, more energy-hungry servers for a relatively small computing job. </p><p>But when memory is pooled and dynamically allocated across different servers, as it is with SDM, the exact amount of required server memory is used. Therefore fewer servers are needed to achieve the same results, and subsequently less power is used. Kove claims that<strong> </strong>Red Hat, in collaboration with the server company <a href=\"https://www.supermicro.com/en/\" target=\"_blank\">Supermicro</a>, measured up to <a href=\"https://stackoverflow.blog/2023/10/30/edge-and-beyond-how-to-meet-the-increasing-demand-for-memory/\" target=\"_blank\">54 percent energy savings</a> by using Kove’s system. <span>This mitigates the need for companies to buy terabyte servers for gigabyte jobs, resulting in cost savings and efficiency gains. </span></p><p>“It takes 200 milliseconds to give the memory,” Overton says, noting that is about how long it takes for a person to blink their eye. “So literally blink your eye and you get the memory you need.”</p><p>One client of Kove’s, the global finance messaging network <a href=\"https://www.swift.com/\" target=\"_blank\">Swift</a>, tested the SDM approach and achieved a 60-fold improvement in speed when training models compared to a virtual machine running the same job on the same hardware, but with the traditional approach to memory. </p><p>“Imagine if a 60-day job took one day, or a one-hour job took one minute. That’s a few clicks away [using our software],” Overton says.</p>",
    "source_feed": "https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss",
    "scraped_at_iso": "2025-05-06T15:47:49Z",
    "selected_image_url": "https://spectrum.ieee.org/media-library/image.jpg?id=60039579&width=1200&height=600&coordinates=0%2C1239%2C0%2C813",
    "filter_verdict": {
        "importance_level": "Interesting",
        "topic": "Hardware",
        "reasoning_summary": "The article discusses a novel approach by Kove to improve computer memory efficiency, which is relevant to AI and tech advancements. While not involving a key entity, the innovation in memory management is significant and factual.",
        "primary_topic_keyword": "memory efficiency innovation"
    },
    "filter_error": null,
    "filtered_at_iso": "2025-05-06T15:47:59Z",
    "topic": "Hardware",
    "is_breaking": false,
    "primary_keyword": "memory efficiency innovation",
    "seo_agent_results": {
        "generated_title_tag": "Memory Efficiency Innovation Speeds Up AI Training",
        "generated_meta_description": "Kove's software-defined memory boosts AI speed and cuts power use by 54%, revolutionizing memory efficiency innovation.",
        "generated_json_ld": "<script type=\"application/ld+json\">  \n{  \n  \"@context\": \"https://schema.org\",  \n  \"@type\": \"NewsArticle\",  \n  \"headline\": \"Memory Efficiency Innovation Speeds Up AI Training\",  \n  \"description\": \"Kove's software-defined memory boosts AI speed and cuts power use by 54%, revolutionizing memory efficiency innovation.\",  \n  \"keywords\": [\"memory efficiency innovation\"],  \n  \"mainEntityOfPage\": { \"@type\": \"WebPage\", \"@id\": \"https://spectrum.ieee.org/computer-memory-ai\" },  \n  \"image\": { \"@type\": \"ImageObject\", \"url\": \"https://spectrum.ieee.org/media-library/image.jpg?id=60039579&width=1200&height=600&coordinates=0%2C1239%2C0%2C813\" },  \n  \"datePublished\": \"2025-05-06T15:00:05Z\",  \n  \"author\": { \"@type\": \"Person\", \"name\": \"AI News Team\" },  \n  \"publisher\": {  \n    \"@type\": \"Organization\",  \n    \"name\": \"Dacoola\",  \n    \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://dacoolaa.netlify.app\" }  \n  }  \n}  \n</script>",
        "generated_article_body_md": "## To Speed up AI, Just Outsource Memory  \n\nKove, a software company, has developed a breakthrough in **memory efficiency innovation** by pooling and dynamically outsourcing computer memory. Their software-defined memory (SDM) system allows external memory to be used more efficiently than local memory, drastically improving performance. For one client, SDM reduced server power consumption by 54%, while another saw a 60-day AI training run completed in just one day. CEO John Overton highlights that SDM strategically divides data processing, keeping critical tasks local while outsourcing less urgent ones, overcoming latency challenges.  \n\n### Why It Matters  \n\nAs AI workloads grow exponentially, memory bottlenecks and energy consumption have become critical hurdles. Kove’s SDM solution not only accelerates processing but also significantly reduces power usage—a major concern in data centers. By optimizing memory allocation, businesses can avoid over-provisioning expensive servers, cutting costs and environmental impact. This innovation could reshape AI scalability, making large-scale training more sustainable and accessible."
    },
    "seo_agent_error": null,
    "generated_tags": [
        "memory efficiency innovation",
        "software-defined memory",
        "AI performance optimization",
        "data center energy reduction",
        "AI training acceleration",
        "Kove SDM technology",
        "memory outsourcing",
        "AI scalability solutions",
        "server power consumption",
        "dynamic memory allocation"
    ],
    "tags_agent_error": null,
    "trend_score": 14.99,
    "slug": "to-speed-up-ai,-just-outsource-memory",
    "audio_url": null,
    "post_template_hash": "7a34e3dba5945832e6f4e2288e1bdc5a445c645dd5f7ce6e39751b31c2a668db"
}