{
    "id": "114be36ab2e121dec66e6e5a2e9ca36f7deaf2bd5a4534eac5fbe7efff988047",
    "title": "Next-generation architectures bridge gap between neural and symbolic representations with neural symbols",
    "link": "https://www.microsoft.com/en-us/research/blog/next-generation-architectures-bridge-gap-between-neural-and-symbolic-representations-with-neural-symbols/",
    "published_iso": "2019-12-12T17:00:46Z",
    "summary": "<p><img alt=\"an equation where x and y are unknowns above an illustration with x and y bouncing through like pinballs until they fall out the bottom as answers\" class=\"alignnone wp-image-627048 size-full\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2019/12/MSResearch_20191204_NeurIPS_Neurosymbolic-AI_1400x788.gif\" width=\"1400\" /><br />\nIn both language and mathematics, symbols and their mutual relationships play a central role. The equation <em>x = 1/y</em> asserts the symbols <em>x </em>and <em>y</em>—that is, what they stand for—are related reciprocally; <em>Kim saw the movie</em> asserts that <em>Kim </em>and <em>the movie</em> are perceiver and stimulus. People are extremely adept with the symbols of language and, with training, become adept with the symbols of mathematics. For many decades, cognitive science explained these human abilities by assuming the presence of symbols in the mind, and AI researchers emulated these abilities by building complex machines for processing symbols. But how could discrete symbols, and the abstract relations between them, be manifested in the neural networks of the brain? The dramatic and recent progress in AI has, in fact, been fueled by replacing the previous symbol-based systems with fundamentally different artificial neural network–based models inspired by the brain. In this new generation of AI systems, is there any place for symbols?</p>\n<p>At <a href=\"https://www.microsoft.com/en-us/research/lab/microsoft-research-ai/\">Microsoft Research AI<span class=\"sr-only\"> (opens in new tab)</span></a>, and in other AI labs, there has been considerable advancement in the development of new types of intelligent systems: neurosymbolic AI models. In neurosymbolic AI, symbol processing and neural network learning collaborate. Using a unique neurosymbolic approach that borrows a mathematical theory of how the brain can encode and process symbols, we at Microsoft Research are building new AI architectures in which neural networks learn to encode and internally process symbols—<em>neural</em> symbols. Neural symbols, technically known as <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://www.sciencedirect.com/science/article/abs/pii/000437029090007M?via%3Dihub\">Tensor Product Representations (TPRs)<span class=\"sr-only\"> (opens in new tab)</span></a>, are patterns of activation distributed over large collections of neurons. Unlike those of standard neural network models, these patterns have a special internal structure that for the first time allows neural computation to process them the way symbols were processed in traditional symbol-based AI systems.</p>\n<p>Two of these new neural architectures—the <a href=\"https://www.microsoft.com/en-us/research/publication/enhancing-the-transformer-with-explicit-relational-encoding-for-math-problem-solving/\">Tensor-Product Transformer (TP-Transformer)<span class=\"sr-only\"> (opens in new tab)</span></a> and <a href=\"https://www.microsoft.com/en-us/research/publication/natural-to-formal-language-generation-using-tensor-product-representations/\">Tensor Products for Natural- to Formal-Language mapping (TP-N2F)<span class=\"sr-only\"> (opens in new tab)</span></a>—have set a new state of the art for AI systems solving math and programming problems stated in natural language. Because these models incorporate neural symbols, they’re not completely opaque, unlike nearly all current AI systems. We can inspect the learned symbols and their mutual relations to begin to understand how the models achieve their remarkable results. We’re presenting both architectures during workshops at the <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://neurips.cc/\">33rd Conference on Neural Information Processing Systems (NeurIPS)<span class=\"sr-only\"> (opens in new tab)</span></a>.</p>\n<h3>Solving math problems</h3>\n<p>The recently released <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/deepmind/mathematics_dataset\">Mathematics Dataset<span class=\"sr-only\"> (opens in new tab)</span></a> contains millions of problems across domains, including algebra, calculus, probability, and number theory, up to the high school level and beyond. Each problem is stated in English and comes with a solution in English. To count as correct, the answer from a model must match character for character the dataset’s answer.</p>\n<p>The TP-Transformer model—the powerful <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://arxiv.org/abs/1706.03762\">Transformer<span class=\"sr-only\"> (opens in new tab)</span></a> architecture enhanced with neural symbols—raised the state-of-the-art overall success level on the dataset from 76 percent to 84 percent. Relative to the previous state of the art, the TP-Transformer outperforms the previous model or performs perfectly in all but one of the 56 mathematical subareas distinguished in the dataset. The following examples of test problems (not seen during learning) from the dataset, along with the (correct) answers generated by our TP-Transformer model, demonstrate the model’s capacity to perform multistep inference in number theory, algebra, and calculus:</p>\n<blockquote><p><em>Suppose 0 = 2*a + 3*a − 150. Let p = 106 − 101. Suppose −3*b + w + 544 = 3*w, −p*b − 5*w = −910. What is the greatest common factor of b and a? </em></p>\n<p><span style=\"color: #008000;\"><em>30</em></span><em>​</em></p>\n<p><em>​<span style=\"text-decoration: line-through;\">​</span></em><em>Let q(l) = 33*l. Let a(y) = −y**2 + 2*y − 2. Let p be a(1). Let d be q(p). Let n = 38 + d. Solve −5*v − 11 = −3*c − 0*v, −4*c = n*v + 32 for c.</em></p>\n<p><span style=\"color: #008000;\"><em>−3</em></span><em>​</em></p>\n<p><em>Let r(g) be the second derivative of 2*g**3/3 − 21*g**2/2 + 10*g. Let z be r(7). Factor −z*s + 6 − 9*s**2 + 0*s + 6*s**2.</em></p>\n<p><span style=\"color: #008000;\"><em>−(s + 3)*(3*s − 2)</em></span><em>​</em></p></blockquote>\n<p>The <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://math-qa.github.io/math-QA\">MathQA dataset<span class=\"sr-only\"> (opens in new tab)</span></a> also consists of a variety of math word problems, but rather than producing answers in English, here the goal is to produce a simple solution program: a sequence of steps, each a primitive operation, consisting of an operator together with the arguments it applies to. Again, to count as correct, a model’s answer must match symbol for symbol the answer provided in the dataset. TP-N2F—a general architecture for taking descriptions in English as inputs and producing outputs in formal languages, such as logic—raised the state-of-the-art success rate from 59 percent to 72 percent.</p>\n<p>The following examples of test problems (not seen during learning) and the (correct) answer produced by TP-N2F demonstrate how much English text the model can read and “understand” and how long a program the model can generate:</p>\n<blockquote><p>​<em>this year , </em><em>mbb</em><em> consulting fired 6 % of its employees and left remaining employee salaries unchanged . sally , a first – year post – </em><em>mba</em><em> consultant , noticed that the average ( arithmetic mean ) of employee salaries at </em><em>mbb</em><em> was 10 % more after the employee headcount reduction than before . the total salary pool allocated to employees after headcount reduction is what percent of that before the headcount reduction ?</em><em>​</em></p>\n<p><span style=\"color: #008000;\"><em>(multiply n1 const_100) (subtract const_100 n0) (add #0 const_100) (add #1 const_4) (multiply #2 #3) (divide #4 #0)</em></span><em>​</em></p>\n<p><em>​</em><em>a high school has 360 students 1 / 2 attend the arithmetic club , 5 / 8 attend the biology club and 3 / 4 attend the chemistry club . 3 / 8 attend all 3 clubs . if every student attends at least one club how many students attend exactly 2 clubs .</em><em>​</em></p>\n<p><span style=\"color: #008000;\"><em>​</em><em>(multiply n0 n1) (multiply n0 n3) (multiply n0 n5) (divide #0 n2) (divide #1 n4) (divide #2 n6) (divide #2 n4) (add #3 #4) (multiply n2 #6) (add #7 #5) (subtract #9 #8) (subtract #10 n0)</em></span><em>​</em></p></blockquote>\n<p>TP-N2F was also applied to another problem, generating Lisp programs from English descriptions: the <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/nearai/program_synthesis/tree/master/program_synthesis/algolisp\">AlgoLisp dataset<span class=\"sr-only\"> (opens in new tab)</span></a>. Again, the new neurosymbolic model substantially improved the state of the art, from 77 percent to 93 percent. Here is an example of its correct performance, a solution consisting of 55 Lisp commands:</p>\n<blockquote><p><em>given numbers a , b , c and e , let d be c , reverse digits in d , let a and the number in the range from 1 to b inclusive that has the maximum value when its digits are reversed be the coordinates of one end and d and e be the coordinates of another end of segment f , find the length of segment f squared</em><em>​</em></p>\n<p><span style=\"color: #008000;\"><em> </em><em>(digits c) (reverse #0) (* arg1 10) (+ #2 arg2) (lambda2 #3) (reduce #1 0 #4) (− a</em> <em>#5) (digits c) (reverse #7) (* arg1 10) (+ #9 arg2) (lambda2 #10) (reduce #8 0 #11) (− a #12) (* #6 #13) (+ b 1) (range 0 #15) (digits arg1) </em><em>​</em><em>(reverse #17) (* arg1 10) (+ #19 arg2) (lambda2 #20) (reduce #18 0 #21) (digits arg2) (reverse #23) (* arg1 10) </em><em>​</em><em>(+ #25 arg2) (lambda2 #26) (reduce #24 0 #27) (> #22 #28) (if #29 arg1 arg2) (lambda2 #30) (reduce #16 0 #31) </em><em>​</em><em>(− #32 e) (+ b 1) (range 0 #34) (digits arg1) (reverse #36) (* arg1 10) (+ #38 arg2) (lambda2 #39) (reduce #37 0 #40) (digits arg2) (reverse #42) (* arg1 10) (+ #44 arg2) (lambda2 #45) (reduce #43 0 #46) (> #41 #47) (if #48 arg1 arg2) </em><em>​</em><em>(lambda2 #49) (reduce #35 0 #50) (− #51 e) (* #33 #52) (+</em> <em>#14 #53)</em></span><em>​</em></p></blockquote>\n<h3>Under the hood</h3>\n<p>With neurosymbolic models, we can peer inside and examine the neural symbols learned and the learned relations between them. In the TP-Transformer model, for example, we find that digits in the denominator of a fraction seek to fill one set of relations, while digits in the numerator seek different relations. When processing the input <em>2/5 + 3/7</em>, we see that to form the ultimate encoding of the symbol <em>5</em>, a query is issued that looks for a division operator for which <em>5</em> is in the denominator; that query matches the first slash.</p>\n<p>These observations are just initial steps in the long process of decoding how the TP-Transformer model manages to perform so well on challenging math problems and to explain why it falls short when it does. But these interpretations of the learned relations between neural symbols are immediately evident, so the prospects are good for developing more sophisticated methods to achieve deep understanding of how these models work.</p>\n<p>In the TP-N2F model of MathQA solution-program generation, we can examine the vectors that the model learns for encoding, for example, the operators. We find that general-purpose operators like <em>add</em>, <em>negate</em>, and <em>log</em> fall in one region of the vector space, while shape-specific geometric computations such as <em>square_area, volume_cylinder, </em>and<em> surface_cube</em> fall into a different region. At one boundary of the space are <em>max, min</em>; at another are <em>factorial, choose </em>(a complex function built from <em>factorial</em>). We begin to see how the model has laid out its learned relation space and can start to analyze how that structure supports its success on its task.</p>\n<h3>The promise of a fundamental shift</h3>\n<p>Symbol processing has been a powerful theory of many of the abilities defining human intelligence, and Microsoft Research’s unique approach to neurosymbolic AI promises significant progress in diverse application areas—progress in creating AI systems that not only perform well, but that can also be understood. Such understanding helps us to explain why a model makes the mistakes it does and enables us to go into the bowels of the model and directly alter the activations of neurons to produce a desired change in behavior. This promises a fundamental shift in the way humans interact with AI models.</p>\n<p>The TP-Transformer release package, which contains the pretrained models, the source code, and a README document describing step-by-step how to reproduce the results reported in the TP-Transformer paper, is available to the public on <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/ischlag/TP-Transformer\">GitHub<span class=\"sr-only\"> (opens in new tab)</span></a>. A similar package for TP-N2F will also be made available on <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/ckzbullbullet/TP-N2F\">GitHub<span class=\"sr-only\"> (opens in new tab)</span></a>. We look forward to ongoing dialogue with the research community on the use of neural symbols in AI.</p>\n<p><div class=\"wp-caption aligncenter\" id=\"attachment_626916\" style=\"width: 583px;\"><img alt=\"The above figure shows the proportion of unseen problems answered correctly for each type of math problem in the Mathematics Dataset for the previous state-of-the-art model (yellow), for the TP-Transformer trained on the same quantity of data (red; 700K steps), and for the TP-Transformer trained on approximately 2.5 times as much data (blue; 1.7M steps).\" class=\"wp-image-626916 size-large\" height=\"1024\" src=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2019/12/TP-Transformer-Math-Problem-Accuracy-573x1024.png\" width=\"573\" /><p class=\"wp-caption-text\" id=\"caption-attachment-626916\">The above figure shows the proportion of unseen problems answered correctly for each type of math problem in the Mathematics Dataset for the previous state-of-the-art model (yellow), for the TP-Transformer trained on the same quantity of data (red; 700K steps), and for the TP-Transformer trained on approximately 2.5 times as much data (blue; 1.7M steps). In all but one subarea, TP-Transformer—a neurosymbolic model—outperforms the previous model or performs perfectly.</p></div><span class=\"sr-only\" id=\"label-external-link\">Opens in a new tab</span></p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/research/blog/next-generation-architectures-bridge-gap-between-neural-and-symbolic-representations-with-neural-symbols/\">Next-generation architectures bridge gap between neural and symbolic representations with neural symbols</a> appeared first on <a href=\"https://www.microsoft.com/en-us/research\">Microsoft Research</a>.</p>",
    "source_feed": "https://www.microsoft.com/en-us/research/blog/category/artificial-intelligence/feed/",
    "scraped_at_iso": "2025-05-03T23:50:16Z",
    "selected_image_url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2019/12/MSResearch_20191204_NeurIPS_Neurosymbolic-AI_1400x788.png",
    "filter_verdict": {
        "importance_level": "Interesting",
        "topic": "Research",
        "reasoning_summary": "The article discusses a novel approach in AI research that bridges neural and symbolic representations, which is a significant and verifiable advancement in the field.",
        "primary_topic_keyword": "neurosymbolic AI research"
    },
    "filter_error": null,
    "filtered_at_iso": "2025-05-03T23:50:32Z",
    "topic": "Research",
    "is_breaking": false,
    "primary_keyword": "neurosymbolic AI research",
    "seo_agent_results": {
        "generated_title_tag": "Neurosymbolic AI Research Bridges Neural and Symbolic Gaps",
        "generated_meta_description": "Microsoft Research advances neurosymbolic AI research with neural symbols, improving math and programming problem-solving accuracy.",
        "generated_json_ld": "<script type=\"application/ld+json\">  \n{  \n  \"@context\": \"https://schema.org\",  \n  \"@type\": \"NewsArticle\",  \n  \"headline\": \"Neurosymbolic AI Research Bridges Neural and Symbolic Gaps\",  \n  \"description\": \"Microsoft Research advances neurosymbolic AI research with neural symbols, improving math and programming problem-solving accuracy.\",  \n  \"keywords\": [\"neurosymbolic AI research\"],  \n  \"mainEntityOfPage\": { \"@type\": \"WebPage\", \"@id\": \"https://www.microsoft.com/en-us/research/blog/next-generation-architectures-bridge-gap-between-neural-and-symbolic-representations-with-neural-symbols/\" },  \n  \"image\": { \"@type\": \"ImageObject\", \"url\": \"https://www.microsoft.com/en-us/research/wp-content/uploads/2019/12/MSResearch_20191204_NeurIPS_Neurosymbolic-AI_1400x788.png\" },  \n  \"datePublished\": \"2019-12-12T17:00:46Z\",  \n  \"author\": { \"@type\": \"Person\", \"name\": \"AI News Team\" },  \n  \"publisher\": {  \n    \"@type\": \"Organization\",  \n    \"name\": \"Dacoola\",  \n    \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://dacoolaa.netlify.app\" }  \n  }  \n}  \n</script>",
        "generated_article_body_md": "## Next-generation architectures bridge gap between neural and symbolic representations with neural symbols  \n\nMicrosoft Research has developed neurosymbolic AI models, including the TP-Transformer and TP-N2F, which combine neural networks with symbolic processing to achieve state-of-the-art results in solving math and programming problems. These models use Tensor Product Representations (TPRs) to encode symbols as neural activations, enabling interpretability and improved accuracy—raising success rates on benchmark datasets by up to 17%.  \n\n### Why It Matters  \n\nNeurosymbolic AI research represents a breakthrough in merging the interpretability of symbolic systems with the learning power of neural networks. By enabling AI models to process abstract relationships—like those in math or programming—these architectures could lead to more transparent and adaptable AI systems. Microsoft’s open-source release of these models encourages broader collaboration, accelerating progress toward explainable AI."
    },
    "seo_agent_error": null,
    "generated_tags": [
        "Neurosymbolic AI",
        "Tensor Product Representations",
        "Microsoft Research",
        "AI Interpretability",
        "TP-Transformer",
        "TP-N2F",
        "Math Problem Solving AI",
        "Programming AI",
        "Explainable AI",
        "AI Benchmark Performance"
    ],
    "tags_agent_error": null,
    "trend_score": 10.0,
    "audio_url": null
}