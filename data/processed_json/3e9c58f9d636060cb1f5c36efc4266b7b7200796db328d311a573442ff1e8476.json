{
    "id": "3e9c58f9d636060cb1f5c36efc4266b7b7200796db328d311a573442ff1e8476",
    "title": "OpenAI and FDA Collaborate on AI in Drug Evaluation to Modernize Approvals",
    "link": "https://www.wired.com/story/openai-fda-doge-ai-drug-evaluation/",
    "published_iso": "2025-05-07T19:59:59Z",
    "summary": "High-ranking OpenAI employees have met with the FDA multiple times in recent weeks to discuss AI and a project called cderGPT.",
    "full_text_content": "The Food and Drug Administration has been meeting with OpenAI to discuss the agency’s use of AI, according to sources with knowledge of the meetings. The meetings appear to be part of a broader effort at the FDA to use this technology to speed up the drug approval process.\n“Why does it take over 10 years for a new drug to come to market?” wrote FDA commissioner Marty Makary on X on Wednesday. “Why are we not modernized with AI and other things? We’ve just completed our first AI-assisted scientific review for a product and that’s just the beginning.”\nThe remarks followed an annual meeting of the American Hospital Association earlier this week, where Makary spoke about AI’s potential to aid in the approval of new treatments for diabetes and certain types of cancer.\nMakary did not specify that OpenAI was part of this initiative. But sources close to the project say a small team from OpenAI has met with the FDA and two associates of Elon Musk's so-called Department of Government Efficiency multiple times in recent weeks. The group has discussed a project called cderGPT, which likely stands for Center for Drug Evaluation, which regulates over-the-counter and prescription drugs in the US, and Research GPT. Jeremy Walsh, who was recently named as the FDA’s first-ever AI officer, has led the discussions. So far, no contract has been signed.\nOpenAI declined to comment.\nWalsh has also met with Peter Bowman-Davis, an undergraduate on leave from Yale who currently serves as the acting chief AI officer at the Department of Health and Human Services, to discuss the FDA’s AI ambitions. Politico first reported the appointment of Bowman-Davis, who is part of Andreessen Horowitz’s American Dynamism team.\nWhen reached via email on Wednesday, Robert Califf, who served as FDA commissioner from 2016 to 2017 and again from 2022 through January, said the agency’s review teams have been using AI for several years now. “It will be interesting to hear the details of which parts of the review were ‘AI assisted’ and what that means,” he says. “There has always been a quest to shorten review times and a broad consensus that AI could help.”\nBefore Califf departed the agency, he said the FDA was considering the various ways AI could be used in internal operations. “Final reviews for approval are only one part of a much larger opportunity,” he says.\nTo be clear, using AI to assist in final drug reviews would represent a chance to compress just a small part of the notoriously long drug-development timeline. The vast majority of drugs fail before ever coming up for FDA review.\nRafael Rosengarten, CEO of Genialis, a precision oncology company, and a cofounder and board member of the Alliance for AI in Healthcare, says he’s in favor of automating certain tasks related to the drug-review process but says there should be policy guidance around what kind of data is used to train AI models and what kind of model performance is considered acceptable. “These machines are incredibly adept at learning information, but they have to be trained in a way so they're learning what we want them to learn,” he says.\nHe could see AI being used more immediately to address certain “low-hanging fruit,” such as checking for application completeness. “Something as trivial as that could expedite the return of feedback to the submitters based on things that need to be addressed to make the application complete,” he says. More sophisticated uses would need to be developed, tested, and proved out.\nAn ex-FDA employee who has tested ChatGPT as a clinical tool says the propensity of AI models to fabricate convincing information raises questions about how reliable such a chatbot might be. “Who knows how robust the platform will be for these reviewers’ tasks,” the ex-staffer says.\nThe FDA review process currently takes about a year, but the agency has several existing mechanisms to expedite that timeline for promising drugs. One of those is the fast track designation, which is for products designed to treat a serious condition and fill an unmet medical need. Another is the breakthrough therapy designation, created in 2012, which allows the FDA to grant priority review to drug candidates that may provide a substantial benefit to patients compared to current treatment options.\n“Ensuring medicines can be reviewed for safety and effectiveness in a timely manner to address patient needs is critical,” says Andrew Powaleny, a spokesperson for the industry group PhRMA, via email. “While AI is still developing, harnessing it requires a thoughtful and risk-based approach with patients at the center.”\nThe FDA is already doing its own research on potential uses of AI. In December 2023 the agency advertised a fellowship for a researcher to develop large language models for internal use. “During participation in this program, the fellow will engage in various activities that include but are not limited to the applications of LLMs for precision medicine, drug development and regulatory science,” the fellowship description says.\nIn January, OpenAI announced ChatGPT Gov, a self-hosted version of its chatbot designed to comply with government regulations. The startup also said it was working toward getting FedRAMP moderate and high accreditations for ChatGPT Enterprise, which would allow it to handle sensitive government data. FedRAMP is a compliance program used by the federal government to assess cloud products; unless authorized through this program, a service cannot hold federal data.\nAdditional reporting by Matt Giles.",
    "content_for_processing": "The Food and Drug Administration has been meeting with OpenAI to discuss the agency’s use of AI, according to sources with knowledge of the meetings. The meetings appear to be part of a broader effort at the FDA to use this technology to speed up the drug approval process.\n“Why does it take over 10 years for a new drug to come to market?” wrote FDA commissioner Marty Makary on X on Wednesday. “Why are we not modernized with AI and other things? We’ve just completed our first AI-assisted scientific review for a product and that’s just the beginning.”\nThe remarks followed an annual meeting of the American Hospital Association earlier this week, where Makary spoke about AI’s potential to aid in the approval of new treatments for diabetes and certain types of cancer.\nMakary did not specify that OpenAI was part of this initiative. But sources close to the project say a small team from OpenAI has met with the FDA and two associates of Elon Musk's so-called Department of Government Efficiency multiple times in recent weeks. The group has discussed a project called cderGPT, which likely stands for Center for Drug Evaluation, which regulates over-the-counter and prescription drugs in the US, and Research GPT. Jeremy Walsh, who was recently named as the FDA’s first-ever AI officer, has led the discussions. So far, no contract has been signed.\nOpenAI declined to comment.\nWalsh has also met with Peter Bowman-Davis, an undergraduate on leave from Yale who currently serves as the acting chief AI officer at the Department of Health and Human Services, to discuss the FDA’s AI ambitions. Politico first reported the appointment of Bowman-Davis, who is part of Andreessen Horowitz’s American Dynamism team.\nWhen reached via email on Wednesday, Robert Califf, who served as FDA commissioner from 2016 to 2017 and again from 2022 through January, said the agency’s review teams have been using AI for several years now. “It will be interesting to hear the details of which parts of the review were ‘AI assisted’ and what that means,” he says. “There has always been a quest to shorten review times and a broad consensus that AI could help.”\nBefore Califf departed the agency, he said the FDA was considering the various ways AI could be used in internal operations. “Final reviews for approval are only one part of a much larger opportunity,” he says.\nTo be clear, using AI to assist in final drug reviews would represent a chance to compress just a small part of the notoriously long drug-development timeline. The vast majority of drugs fail before ever coming up for FDA review.\nRafael Rosengarten, CEO of Genialis, a precision oncology company, and a cofounder and board member of the Alliance for AI in Healthcare, says he’s in favor of automating certain tasks related to the drug-review process but says there should be policy guidance around what kind of data is used to train AI models and what kind of model performance is considered acceptable. “These machines are incredibly adept at learning information, but they have to be trained in a way so they're learning what we want them to learn,” he says.\nHe could see AI being used more immediately to address certain “low-hanging fruit,” such as checking for application completeness. “Something as trivial as that could expedite the return of feedback to the submitters based on things that need to be addressed to make the application complete,” he says. More sophisticated uses would need to be developed, tested, and proved out.\nAn ex-FDA employee who has tested ChatGPT as a clinical tool says the propensity of AI models to fabricate convincing information raises questions about how reliable such a chatbot might be. “Who knows how robust the platform will be for these reviewers’ tasks,” the ex-staffer says.\nThe FDA review process currently takes about a year, but the agency has several existing mechanisms to expedite that timeline for promising drugs. One of those is the fast track designation, which is for products designed to treat a serious condition and fill an unmet medical need. Another is the breakthrough therapy designation, created in 2012, which allows the FDA to grant priority review to drug candidates that may provide a substantial benefit to patients compared to current treatment options.\n“Ensuring medicines can be reviewed for safety and effectiveness in a timely manner to address patient needs is critical,” says Andrew Powaleny, a spokesperson for the industry group PhRMA, via email. “While AI is still developing, harnessing it requires a thoughtful and risk-based approach with patients at the center.”\nThe FDA is already doing its own research on potential uses of AI. In December 2023 the agency advertised a fellowship for a researcher to develop large language models for internal use. “During participation in this program, the fellow will engage in various activities that include but are not limited to the applications of LLMs for precision medicine, drug development and regulatory science,” the fellowship description says.\nIn January, OpenAI announced ChatGPT Gov, a self-hosted version of its chatbot designed to comply with government regulations. The startup also said it was working toward getting FedRAMP moderate and high accreditations for ChatGPT Enterprise, which would allow it to handle sensitive government data. FedRAMP is a compliance program used by the federal government to assess cloud products; unless authorized through this program, a service cannot hold federal data.\nAdditional reporting by Matt Giles.",
    "source_feed": "https://www.wired.com/feed/tag/ai/latest/rss",
    "scraped_at_iso": "2025-05-07T20:40:33Z",
    "selected_image_url": "https://media.wired.com/photos/681ba1b6c38af307cb440ad9/191:100/w_1280,c_limit/openai-fda-biz-2210029399.jpg",
    "filter_verdict": {
        "importance_level": "Interesting",
        "topic": "Health",
        "reasoning_summary": "OpenAI is a key company, and discussions with the FDA about AI in drug evaluation represent a significant, verifiable development in AI applications for health.",
        "primary_topic_keyword": "AI in drug evaluation"
    },
    "filter_error": null,
    "filtered_at_iso": "2025-05-07T20:40:43Z",
    "topic": "Health",
    "is_breaking": false,
    "primary_keyword": "AI in drug evaluation",
    "seo_agent_results": {
        "generated_title_tag": "OpenAI & FDA Discuss AI in Drug Evaluation to Speed Approvals",
        "generated_meta_description": "OpenAI and the FDA are exploring AI in drug evaluation to accelerate approvals. Learn how AI could transform regulatory processes.",
        "generated_seo_h1": "OpenAI and FDA Collaborate on AI in Drug Evaluation to Modernize Approvals",
        "generated_json_ld": "<script type=\"application/ld+json\">  \n{  \n  \"@context\": \"https://schema.org\",  \n  \"@type\": \"NewsArticle\",  \n  \"headline\": \"OpenAI and FDA Collaborate on AI in Drug Evaluation to Modernize Approvals\",  \n  \"description\": \"OpenAI and the FDA are exploring AI in drug evaluation to accelerate approvals. Learn how AI could transform regulatory processes.\",  \n  \"keywords\": [\"AI in drug evaluation\"],  \n  \"mainEntityOfPage\": { \"@type\": \"WebPage\", \"@id\": \"https://www.wired.com/story/openai-fda-doge-ai-drug-evaluation/\" },  \n  \"image\": { \"@type\": \"ImageObject\", \"url\": \"https://media.wired.com/photos/681ba1b6c38af307cb440ad9/191:100/w_1280,c_limit/openai-fda-biz-2210029399.jpg\" },  \n  \"datePublished\": \"2025-05-07T19:59:59Z\",  \n  \"author\": { \"@type\": \"Person\", \"name\": \"AI News Team\" },  \n  \"publisher\": {  \n    \"@type\": \"Organization\",  \n    \"name\": \"Dacoola\",  \n    \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://dacoolaa.netlify.app\" }  \n  }  \n}  \n</script>",
        "generated_article_body_md": "## OpenAI and FDA Collaborate on AI in Drug Evaluation to Modernize Approvals  \n\nThe FDA is in talks with OpenAI to explore how artificial intelligence (AI) can streamline the drug evaluation process, potentially reducing the time it takes for new treatments to reach patients. Sources reveal that discussions involve a project called **cderGPT**, likely referencing the FDA’s Center for Drug Evaluation and Research (CDER). FDA Commissioner Marty Makary has emphasized the need to modernize regulatory processes with AI, citing its potential to assist in scientific reviews for diabetes and cancer treatments. While no formal agreement has been reached, these talks signal a growing push to integrate AI into drug approval workflows.  \n\n### How AI Could Revolutionize Drug Evaluation  \n\nThe FDA’s interest in **AI in drug evaluation** aligns with broader efforts to shorten review times, which currently average about a year. AI could automate administrative tasks—such as checking application completeness—while more advanced applications might assist in data analysis and risk assessment. Jeremy Walsh, the FDA’s first AI officer, is leading discussions with OpenAI and other stakeholders, including HHS’s acting chief AI officer, Peter Bowman-Davis.  \n\nFormer FDA Commissioner Robert Califf notes that AI has been used internally for years, but its role in final approvals remains limited. Rafael Rosengarten of Genialis advocates for AI adoption but stresses the need for clear guidelines on model training and performance standards to ensure reliability.  \n\n#### Potential Benefits and Risks  \n\n<div class=\"pros-cons-container\">  \n  <div class=\"pros-section\">  \n    <h5 class=\"section-title\">Pros</h5>  \n    <div class=\"item-list\">  \n      - **Faster Approvals:** AI could reduce bottlenecks in reviewing drug applications.  \n      - **Precision Medicine:** LLMs might enhance personalized treatment evaluations.  \n    </div>  \n  </div>  \n  <div class=\"cons-section\">  \n    <h5 class=\"section-title\">Cons</h5>  \n    <div class=\"item-list\">  \n      - **Hallucination Risks:** AI-generated inaccuracies could compromise safety.  \n      - **Regulatory Gaps:** Lack of clear policies for AI-assisted decisions.  \n    </div>  \n  </div>  \n</div>  \n\n#### Challenges and Ethical Considerations  \n\nCritics highlight concerns about AI’s reliability, particularly its tendency to \"hallucinate\" plausible but false information. An ex-FDA employee warns that unchecked AI integration could introduce errors into critical reviews. Meanwhile, OpenAI is developing **ChatGPT Gov**, a government-compliant version of its model, aiming for FedRAMP certification to handle sensitive data.  \n\n#### What’s Next?  \n\nThe FDA is already researching AI applications, including a fellowship for LLM development in drug regulation. If successful, AI could eventually expand beyond administrative tasks to assist in clinical trial analysis and post-market surveillance. However, as PhRMA’s Andrew Powaleny notes, patient safety must remain the priority in any AI adoption.  \n\n#### Frequently Asked Questions  \n\n<div class=\"faq-section\">  \n  <details class=\"faq-item\">  \n    <summary class=\"faq-question\">What is cderGPT?</summary>  \n    <div class=\"faq-answer-content\">  \n      <p>A potential AI tool being discussed between OpenAI and the FDA, likely tied to the Center for Drug Evaluation and Research (CDER).</p>  \n    </div>  \n  </details>  \n  <details class=\"faq-item\">  \n    <summary class=\"faq-question\">How could AI speed up drug approvals?</summary>  \n    <div class=\"faq-answer-content\">  \n      <p>By automating routine checks, analyzing large datasets, and flagging inconsistencies in applications.</p>  \n    </div>  \n  </details>  \n</div>"
    },
    "seo_agent_error": null,
    "generated_tags": [
        "AI in drug evaluation",
        "FDA and OpenAI collaboration",
        "cderGPT",
        "AI in healthcare",
        "drug approval modernization",
        "AI for precision medicine",
        "regulatory AI challenges",
        "ChatGPT Gov",
        "AI in clinical trials",
        "FDA AI officer"
    ],
    "tags_agent_error": null,
    "trend_score": 15.0,
    "slug": "openai-and-fda-collaborate-on-ai-in-drug-evaluation-to-modernize-approvals",
    "audio_url": null,
    "post_template_hash": "7a34e3dba5945832e6f4e2288e1bdc5a445c645dd5f7ce6e39751b31c2a668db"
}