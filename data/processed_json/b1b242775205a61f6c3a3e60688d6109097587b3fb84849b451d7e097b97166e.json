{
    "id": "b1b242775205a61f6c3a3e60688d6109097587b3fb84849b451d7e097b97166e",
    "title": "WhatsApp defends 'optional' AI tool that cannot be turned off",
    "link": "https://www.bbc.com/news/articles/cd7vzw78gz9o",
    "published_iso": "2025-04-23T14:26:00Z",
    "summary": "While Meta says the AI chatbot is a \"good thing\", some users have shared their frustrations.",
    "full_text_content": "WhatsApp defends 'optional' AI tool that cannot be turned off\nWhatsApp says its new AI feature embedded in the messaging service is \"entirely optional\" - despite the fact it cannot be removed from the app.\nThe Meta AI logo is an ever-present blue circle with pink and green splashes in the bottom right of your Chats screen.\nInteracting with it opens a chatbot designed to answer your questions, but it has drawn attention and frustration from users who cannot remove it from the app.\nIt follows Microsoft's Recall feature, which was an always-on tool - before the firm faced a backlash and decided to allow people to disable it.\n\"We think giving people these options is a good thing and we're always listening to feedback from our users,\" WhatsApp told the BBC.\nThe company likens the feature to other permanent options in the app like 'channels' and 'status'.\nIt comes the same week Meta announced an update to its teen accounts feature on Instagram.\nThe firm revealed it was testing AI technology in the US designed to find accounts belonging to teenagers who have lied about their age on the platform.\nWhere is the new blue circle?\nIf you can't see it, you may not be able to use it yet.\nMeta says the feature is only being rolled out to some countries at the moment and advises it \"might not be available to you yet, even if other users in your country have access\".\nAs well as the blue circle, there is a search bar at the top inviting users to 'Ask Meta AI or Search'.\nThis is also a feature on Facebook Messenger and Instagram, with both platforms owned by Meta.\nIts AI chatbot is powered by Llama 4, one of the large language models operated by Meta.\nBefore you ask it anything, there is a long message from Meta explaining what Meta AI is - stating it is \"optional\".\nOn its website, WhatsApp says Meta AI \"can answer your questions, teach you something, or help come up with new ideas\".\nI tried out the feature by asking the AI what the weather was like in Glasgow, and it responded in seconds with a detailed report on temperature, the chance of rain, wind and humidity.\nIt also gave me two links for further information, but this is where it ran into problems.\nOne of the links was relevant, but the other tried to give me additional weather details for Charing Cross - not the location in Glasgow, but the railway station in London.\nWhat do people think of it?\nSo far in Europe people aren't very pleased, with users on X, Bluesky, and Reddit outlining their frustrations - and Guardian columnist Polly Hudson was among those venting their anger at not being able to turn it off.\nDr Kris Shrishak, an adviser on AI and privacy, was also highly critical, and accused Meta of \"exploiting its existing market\" and \"using people as test subjects for AI\".\n\"No one should be forced to use AI,\" he told the BBC.\n\"Its AI models are a privacy violation by design - Meta, through web scraping, has used personal data of people and pirated books in training them.\n\"Now that the legality of their approach has been challenged in courts, Meta is looking for other sources to collect data from people, and this feature could be one such source.\"\nAn investigation by The Atlantic revealed Meta may have accessed millions of pirated books and research papers through LibGen - Library Genesis - to train its Llama AI.\nAuthor groups across the UK and around the world are organising campaigns to encourage governments to intervene, and Meta is currently defending a court case brought by multiple authors over the use of their work.\nA spokesperson for Meta declined to comment on The Atlantic investigation.\nWhat are the concerns?\nWhen you first use Meta AI in WhatsApp, it states the chatbot \"can only read messages people share with it\".\n\"Meta can't read any other messages in your personal chats, as your personal messages remain end to end encrypted,\" it says.\nMeanwhile the Information Commissioner's Office told the BBC it would \"continue to monitor the adoption of Meta AI's technology and use of personal data within WhatsApp\".\n\"Personal information fuels much of AI innovation so people need to trust that organisations are using their information responsibly,\" it said.\n\"Organisations who want to use people's personal details to train or use generative AI models need to comply with all their data protection obligations, and take the necessary extra steps when it comes to processing the data of children.\"\nDr Shrishak says users should be wary.\n\"When you send messages to your friend, end to end encryption will not be affected,\" he said.\n\"Every time you use this feature and communicate with Meta AI, you need to remember that one of the ends is Meta, not your friend.\"\nThe tech giant also highlights that you should only share material which you know could be used by others.\n\"Don't share information, including sensitive topics, about others or yourself that you don't want the AI to retain and use,\" it says.\nAdditional reporting by Joe Tidy",
    "content_for_processing": "WhatsApp defends 'optional' AI tool that cannot be turned off\nWhatsApp says its new AI feature embedded in the messaging service is \"entirely optional\" - despite the fact it cannot be removed from the app.\nThe Meta AI logo is an ever-present blue circle with pink and green splashes in the bottom right of your Chats screen.\nInteracting with it opens a chatbot designed to answer your questions, but it has drawn attention and frustration from users who cannot remove it from the app.\nIt follows Microsoft's Recall feature, which was an always-on tool - before the firm faced a backlash and decided to allow people to disable it.\n\"We think giving people these options is a good thing and we're always listening to feedback from our users,\" WhatsApp told the BBC.\nThe company likens the feature to other permanent options in the app like 'channels' and 'status'.\nIt comes the same week Meta announced an update to its teen accounts feature on Instagram.\nThe firm revealed it was testing AI technology in the US designed to find accounts belonging to teenagers who have lied about their age on the platform.\nWhere is the new blue circle?\nIf you can't see it, you may not be able to use it yet.\nMeta says the feature is only being rolled out to some countries at the moment and advises it \"might not be available to you yet, even if other users in your country have access\".\nAs well as the blue circle, there is a search bar at the top inviting users to 'Ask Meta AI or Search'.\nThis is also a feature on Facebook Messenger and Instagram, with both platforms owned by Meta.\nIts AI chatbot is powered by Llama 4, one of the large language models operated by Meta.\nBefore you ask it anything, there is a long message from Meta explaining what Meta AI is - stating it is \"optional\".\nOn its website, WhatsApp says Meta AI \"can answer your questions, teach you something, or help come up with new ideas\".\nI tried out the feature by asking the AI what the weather was like in Glasgow, and it responded in seconds with a detailed report on temperature, the chance of rain, wind and humidity.\nIt also gave me two links for further information, but this is where it ran into problems.\nOne of the links was relevant, but the other tried to give me additional weather details for Charing Cross - not the location in Glasgow, but the railway station in London.\nWhat do people think of it?\nSo far in Europe people aren't very pleased, with users on X, Bluesky, and Reddit outlining their frustrations - and Guardian columnist Polly Hudson was among those venting their anger at not being able to turn it off.\nDr Kris Shrishak, an adviser on AI and privacy, was also highly critical, and accused Meta of \"exploiting its existing market\" and \"using people as test subjects for AI\".\n\"No one should be forced to use AI,\" he told the BBC.\n\"Its AI models are a privacy violation by design - Meta, through web scraping, has used personal data of people and pirated books in training them.\n\"Now that the legality of their approach has been challenged in courts, Meta is looking for other sources to collect data from people, and this feature could be one such source.\"\nAn investigation by The Atlantic revealed Meta may have accessed millions of pirated books and research papers through LibGen - Library Genesis - to train its Llama AI.\nAuthor groups across the UK and around the world are organising campaigns to encourage governments to intervene, and Meta is currently defending a court case brought by multiple authors over the use of their work.\nA spokesperson for Meta declined to comment on The Atlantic investigation.\nWhat are the concerns?\nWhen you first use Meta AI in WhatsApp, it states the chatbot \"can only read messages people share with it\".\n\"Meta can't read any other messages in your personal chats, as your personal messages remain end to end encrypted,\" it says.\nMeanwhile the Information Commissioner's Office told the BBC it would \"continue to monitor the adoption of Meta AI's technology and use of personal data within WhatsApp\".\n\"Personal information fuels much of AI innovation so people need to trust that organisations are using their information responsibly,\" it said.\n\"Organisations who want to use people's personal details to train or use generative AI models need to comply with all their data protection obligations, and take the necessary extra steps when it comes to processing the data of children.\"\nDr Shrishak says users should be wary.\n\"When you send messages to your friend, end to end encryption will not be affected,\" he said.\n\"Every time you use this feature and communicate with Meta AI, you need to remember that one of the ends is Meta, not your friend.\"\nThe tech giant also highlights that you should only share material which you know could be used by others.\n\"Don't share information, including sensitive topics, about others or yourself that you don't want the AI to retain and use,\" it says.\nAdditional reporting by Joe Tidy",
    "source_feed": "https://feeds.bbci.co.uk/news/technology/rss.xml",
    "scraped_at_iso": "2025-05-07T10:46:59Z",
    "selected_image_url": "https://ichef.bbci.co.uk/news/1024/branded_news/821f/live/010a6e10-1f79-11f0-bdfc-33d5f1a51c32.jpg",
    "filter_verdict": {
        "importance_level": "Interesting",
        "topic": "Software",
        "reasoning_summary": "Meta's WhatsApp AI tool is a key entity product, making it at least Interesting, but the issue is not urgent or high-impact enough to be Breaking.",
        "primary_topic_keyword": "WhatsApp AI tool"
    },
    "filter_error": null,
    "filtered_at_iso": "2025-05-07T10:48:23Z",
    "topic": "Software",
    "is_breaking": false,
    "primary_keyword": "WhatsApp AI tool",
    "seo_agent_results": {
        "generated_title_tag": "WhatsApp AI Tool: Why Users Can't Disable the \"Optional\" Feature",
        "generated_meta_description": "WhatsApp defends its AI tool as \"optional\" despite users being unable to disable it. Learn about privacy concerns, backlash, and Meta's response.",
        "generated_seo_h1": "WhatsApp’s \"Optional\" AI Tool Sparks Backlash Over Non-Removable Feature",
        "generated_json_ld": "<script type=\"application/ld+json\">  \n{  \n  \"@context\": \"https://schema.org\",  \n  \"@type\": \"NewsArticle\",  \n  \"headline\": \"WhatsApp’s \"Optional\" AI Tool Sparks Backlash Over Non-Removable Feature\",  \n  \"description\": \"WhatsApp defends its AI tool as \"optional\" despite users being unable to disable it. Learn about privacy concerns, backlash, and Meta's response.\",  \n  \"keywords\": [\"WhatsApp AI tool\"],  \n  \"mainEntityOfPage\": { \"@type\": \"WebPage\", \"@id\": \"https://www.bbc.com/news/articles/cd7vzw78gz9o\" },  \n  \"image\": { \"@type\": \"ImageObject\", \"url\": \"https://ichef.bbci.co.uk/news/1024/branded_news/821f/live/010a6e10-1f79-11f0-bdfc-33d5f1a51c32.jpg\" },  \n  \"datePublished\": \"2025-04-23T14:26:00Z\",  \n  \"author\": { \"@type\": \"Person\", \"name\": \"AI News Team\" },  \n  \"publisher\": {  \n    \"@type\": \"Organization\",  \n    \"name\": \"Dacoola\",  \n    \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://dacoolaa.netlify.app\" }  \n  }  \n}  \n</script>",
        "generated_article_body_md": "## WhatsApp’s \"Optional\" AI Tool Sparks Backlash Over Non-Removable Feature  \n\nWhatsApp has introduced a new AI-powered chatbot feature, Meta AI, which appears as a persistent blue circle in the app’s chat interface. Despite being labeled as \"optional,\" users cannot remove or disable the **WhatsApp AI tool**, leading to frustration and privacy concerns. Meta compares the feature to other permanent elements like WhatsApp Status and Channels, but critics argue it forces AI interaction on unwilling users.  \n\nThe AI chatbot, powered by Meta’s Llama 4 language model, provides answers to user queries but has faced criticism for inaccuracies—such as linking incorrect weather data—and concerns over data privacy. Similar to Microsoft’s controversial Recall feature, Meta’s approach has drawn scrutiny from privacy advocates and regulators.  \n\n### Why WhatsApp’s AI Tool Is Stirring Controversy  \n\nMeta insists the **WhatsApp AI tool** is designed to enhance user experience, offering quick answers and creative suggestions. However, the inability to disable it has led to backlash, particularly in Europe, where users on platforms like X and Reddit have voiced dissatisfaction. Privacy experts, including Dr. Kris Shrishak, accuse Meta of exploiting its market dominance to gather additional training data for its AI models.  \n\nAn investigation by *The Atlantic* revealed Meta may have used pirated books and research papers to train Llama, further fueling legal challenges from authors. While WhatsApp assures users that personal chats remain end-to-end encrypted, interactions with Meta AI are processed by the company, raising concerns about data retention and usage.  \n\n#### Privacy and Ethical Concerns  \n\n<div class=\"pros-cons-container\">  \n  <div class=\"pros-section\">  \n    <h5 class=\"section-title\">Pros</h5>  \n    <div class=\"item-list\">  \n      - Provides quick answers and creative suggestions  \n      - Integrated seamlessly into WhatsApp’s interface  \n    </div>  \n  </div>  \n  <div class=\"cons-section\">  \n    <h5 class=\"section-title\">Cons</h5>  \n    <div class=\"item-list\">  \n      - Cannot be disabled or removed  \n      - Potential privacy risks from AI data processing  \n      - Inaccurate responses in some cases  \n    </div>  \n  </div>  \n</div>  \n\n#### Frequently Asked Questions  \n\n<div class=\"faq-section\">  \n  <details class=\"faq-item\">  \n    <summary class=\"faq-question\">Can I remove the WhatsApp AI tool from my app?</summary>  \n    <div class=\"faq-answer-content\">  \n      <p>No, Meta has confirmed that the AI feature cannot be disabled or removed, despite being labeled as \"optional.\"</p>  \n    </div>  \n  </details>  \n  <details class=\"faq-item\">  \n    <summary class=\"faq-question\">Is my chat data safe with Meta AI?</summary>  \n    <div class=\"faq-answer-content\">  \n      <p>WhatsApp states that personal chats remain end-to-end encrypted, but messages sent to Meta AI are processed by the company, raising privacy concerns.</p>  \n    </div>  \n  </details>  \n</div>"
    },
    "seo_agent_error": "JSON-LD content invalid.",
    "generated_tags": [
        "WhatsApp AI Tool",
        "Meta AI",
        "AI Privacy Concerns",
        "Llama 4 Language Model",
        "WhatsApp Features",
        "AI Ethics",
        "Data Privacy",
        "Meta Controversy",
        "AI Chatbot",
        "End-to-End Encryption"
    ],
    "tags_agent_error": null,
    "trend_score": 12.69,
    "slug": "whatsapp-defends-optional-ai-tool-that-cannot-be-turned-off",
    "audio_url": null,
    "post_template_hash": "e014798308478eaefcc5b1d461813eb07fed9c56caa5076dd739ac559c2529aa"
}