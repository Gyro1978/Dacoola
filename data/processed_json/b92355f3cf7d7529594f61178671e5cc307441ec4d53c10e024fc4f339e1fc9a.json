{
    "id": "b92355f3cf7d7529594f61178671e5cc307441ec4d53c10e024fc4f339e1fc9a",
    "title": "NVIDIA Research at ICLR — Pioneering the Next Wave of Multimodal Generative AI",
    "link": "https://blogs.nvidia.com/blog/ai-research-iclr-2025/",
    "published_iso": "2025-04-24T13:00:48Z",
    "summary": "<div id=\"bsf_rt_marker\"></div><p>Advancing AI requires a full-stack approach, with a powerful foundation of computing infrastructure — including accelerated processors and networking technologies — connected to optimized compilers, algorithms and applications.</p>\n<p><a href=\"https://www.nvidia.com/en-us/research/\" target=\"_blank\">NVIDIA Research</a> is innovating across this spectrum, supporting virtually every industry in the process. At this week’s <a href=\"https://iclr.cc/\" target=\"_blank\">International Conference on Learning Representations</a> (ICLR), taking place April 24-28 in Singapore, more than 70 NVIDIA-authored papers introduce AI developments with applications in autonomous vehicles, healthcare, multimodal content creation, robotics and more.</p>\n<p>“ICLR is one of the world’s most impactful AI conferences, where researchers introduce important technical innovations that move every industry forward,” said Bryan Catanzaro, vice president of applied deep learning research at NVIDIA. “The research we’re contributing this year aims to accelerate every level of the computing stack to amplify the impact and utility of AI across industries.”</p>\n<p></p>\n<h2><b>Research That Tackles Real-World Challenges</b></h2>\n<p>Several <a href=\"https://research.nvidia.com/publications?f%5B0%5D=publication_events%3A38\" target=\"_blank\">NVIDIA-authored papers at ICLR</a> cover groundbreaking work in multimodal generative AI and novel methods for AI training and synthetic data generation, including: <b></b></p>\n<ul>\n<li><a href=\"https://blogs.nvidia.com/blog/fugatto-gen-ai-sound-model/\"><b>Fugatto</b></a>: The world’s most flexible audio generative AI model, Fugatto generates or transforms any mix of music, voices and sounds described with prompts using any combination of text and audio files. Other NVIDIA models at ICLR improve audio large language models (<a href=\"https://www.nvidia.com/en-us/glossary/large-language-models/\" target=\"_blank\">LLMs</a>) to better understand speech.</li>\n<li><a href=\"https://hamster-robot.github.io/\" target=\"_blank\"><b>HAMSTER</b></a>: This paper demonstrates that a hierarchical design for vision-language-action models can improve their ability to transfer knowledge from off-domain fine-tuning data — inexpensive data that doesn’t need to be collected on actual robot hardware — to improve a robot’s skills in testing scenarios. <b>  </b></li>\n<li><a href=\"https://developer.nvidia.com/blog/hymba-hybrid-head-architecture-boosts-small-language-model-performance/\" target=\"_blank\"><b>Hymba</b></a>: This family of small language models uses a hybrid model architecture to create LLMs that blend the benefits of transformer models and state space models, enabling high-resolution recall, efficient context summarization and common-sense reasoning tasks. With its hybrid approach, Hymba improves throughput by 3x and reduces cache by almost 4x without sacrificing performance.</li>\n<li><a href=\"https://hanlab.mit.edu/projects/longvila\" target=\"_blank\"><b>LongVILA</b></a>: This training pipeline enables efficient visual language model training and inference for long video understanding. Training AI models on long videos is compute and memory-intensive — so this paper introduces a system that efficiently parallelizes long video training and inference, with training scalability up to 2 million tokens on 256 GPUs. LongVILA achieves state-of-the-art performance across nine popular video benchmarks.</li>\n<li><a href=\"https://openreview.net/forum?id=AyC4uxx2HW\" target=\"_blank\"><b>LLaMaFlex</b></a>: This paper introduces a new zero-shot generation technique to create a family of compressed LLMs based on one large model. The researchers found that LLaMaFlex can generate compressed models that are as accurate or better than state-of-the art pruned, flexible and trained-from-scratch models — a capability that could be applied to significantly reduce the cost of training model families compared to techniques like pruning and knowledge distillation.</li>\n<li><a href=\"https://research.nvidia.com/labs/genair/proteina/\" target=\"_blank\"><b>Proteina</b></a>: This model can generate diverse and designable protein backbones, the framework that holds a protein together. It uses a <a href=\"https://blogs.nvidia.com/blog/what-is-a-transformer-model/\">transformer model architecture</a> with up to 5x as many parameters as previous models.</li>\n<li><a href=\"https://arxiv.org/abs/2503.04538\" target=\"_blank\"><b>SRSA</b></a>: This framework addresses the challenge of teaching robots new tasks using a preexisting skill library — so instead of learning from scratch, a robot can apply and adapt its existing skills to the new task. By developing a framework to predict which preexisting skill would be most relevant to a new task, the researchers were able to improve zero-shot success rates on unseen tasks by 19%.</li>\n<li><a href=\"https://jiawei-yang.github.io/STORM/\" target=\"_blank\"><b>STORM</b></a>: This model can reconstruct dynamic outdoor scenes — like cars driving or trees swaying in the wind — with a precise 3D representation inferred from just a few snapshots. The model, which can reconstruct large-scale outdoor scenes in 200 milliseconds, has potential applications in autonomous vehicle development.</li>\n</ul>\n<p><i>Discover the </i><a href=\"https://research.nvidia.com/publications\" target=\"_blank\"><i>latest work</i></a><i> from </i><a href=\"https://www.nvidia.com/en-us/research/\" target=\"_blank\"><i>NVIDIA Research</i></a><i>, a global team of around 400 experts in fields including computer architecture, generative AI, graphics, self-driving cars and robotics. </i></p>",
    "source_feed": "https://blogs.nvidia.com/feed/",
    "scraped_at_iso": "2025-05-02T22:42:06Z",
    "filter_verdict": {
        "importance_level": "Interesting",
        "topic": "Research",
        "reasoning_summary": "NVIDIA Research presenting over 70 papers at ICLR, a major AI conference, with applications across multiple industries, indicating significant research contributions.",
        "primary_topic_keyword": "NVIDIA AI research"
    },
    "filter_error": null,
    "filtered_at_iso": "2025-05-02T22:49:34Z",
    "topic": "Research",
    "is_breaking": false,
    "primary_keyword": "NVIDIA AI research",
    "similarity_check_error": null,
    "selected_image_url": "https://blogs.nvidia.com/wp-content/uploads/2025/04/ICLR_featuredstill.jpg",
    "seo_agent_results": {
        "generated_title_tag": "NVIDIA AI Research Unveils Breakthroughs at ICLR 2025",
        "generated_meta_description": "NVIDIA AI research showcases 70+ papers at ICLR 2025, advancing multimodal generative AI, robotics, and more. Discover the innovations.",
        "generated_json_ld": "<script type=\"application/ld+json\">  \n{  \n  \"@context\": \"https://schema.org\",  \n  \"@type\": \"NewsArticle\",  \n  \"headline\": \"NVIDIA AI Research Unveils Breakthroughs at ICLR 2025\",  \n  \"description\": \"NVIDIA AI research showcases 70+ papers at ICLR 2025, advancing multimodal generative AI, robotics, and more. Discover the innovations.\",  \n  \"keywords\": [\"NVIDIA AI research\"],  \n  \"mainEntityOfPage\": { \"@type\": \"WebPage\", \"@id\": \"https://blogs.nvidia.com/blog/ai-research-iclr-2025/\" },  \n  \"image\": { \"@type\": \"ImageObject\", \"url\": \"https://blogs.nvidia.com/wp-content/uploads/2025/04/ICLR_featuredstill.jpg\" },  \n  \"datePublished\": \"2025-04-24T13:00:48Z\",  \n  \"author\": { \"@type\": \"Person\", \"name\": \"AI News Team\" },  \n  \"publisher\": {  \n    \"@type\": \"Organization\",  \n    \"name\": \"Dacoola\",  \n    \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://i.imgur.com/A5Wdp6f.png\" }  \n  }  \n}  \n</script>",
        "generated_article_body_md": "## NVIDIA Research at ICLR — Pioneering the Next Wave of Multimodal Generative AI  \n\nNVIDIA Research is pushing the boundaries of AI with a full-stack approach, combining accelerated computing infrastructure, optimized algorithms, and real-world applications. At the International Conference on Learning Representations (ICLR) 2025 in Singapore, the company presented over 70 papers spanning autonomous vehicles, healthcare, robotics, and multimodal content creation. Bryan Catanzaro, NVIDIA’s VP of applied deep learning research, emphasized the conference’s role in driving industry-wide AI advancements.  \n\nAmong the standout innovations is **Fugatto**, a highly flexible audio generative AI model capable of transforming or creating music, voices, and sounds using text or audio prompts. Another breakthrough, **HAMSTER**, improves robot learning by leveraging off-domain data for better real-world performance. Meanwhile, **Hymba**, a hybrid small language model, enhances reasoning tasks while boosting efficiency by 3x in throughput and reducing cache usage by nearly 4x.  \n\n### Advancing AI Efficiency and Capabilities  \nNVIDIA’s research also tackles computational challenges. **LongVILA** optimizes training for long video understanding, scaling up to 2 million tokens across 256 GPUs. **LLaMaFlex** introduces zero-shot compression for large language models, reducing training costs without sacrificing accuracy. In robotics, **SRSA** improves task adaptation by predicting relevant preexisting skills, increasing zero-shot success rates by 19%. Additionally, **Proteina** generates diverse protein backbones using a transformer model with 5x more parameters than previous solutions.  \n\nThese innovations highlight NVIDIA’s commitment to solving real-world AI challenges, from healthcare to autonomous systems, reinforcing its leadership in **NVIDIA AI research**."
    },
    "seo_agent_error": null,
    "generated_tags": [
        "NVIDIA Research",
        "Multimodal Generative AI",
        "ICLR 2025",
        "AI Innovations",
        "Fugatto Audio AI",
        "HAMSTER Robotics",
        "Hymba Language Model",
        "LongVILA Video Understanding",
        "LLaMaFlex Compression",
        "Proteina Protein Generation"
    ],
    "tags_agent_error": null,
    "trend_score": 10.0,
    "slug": "nvidia-research-at-iclr-pioneering-the-next-wave-of-multimodal-generative-ai",
    "audio_url": null,
    "post_template_hash": "e014798308478eaefcc5b1d461813eb07fed9c56caa5076dd739ac559c2529aa"
}