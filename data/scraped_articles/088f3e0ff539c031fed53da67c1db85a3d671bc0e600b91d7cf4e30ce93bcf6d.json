{
    "id": "088f3e0ff539c031fed53da67c1db85a3d671bc0e600b91d7cf4e30ce93bcf6d",
    "title": "Hidden costs in AI deployment: Why Claude models may be 20-30% more expensive than GPT in enterprise settings",
    "link": "https://venturebeat.com/ai/hidden-costs-in-ai-deployment-why-claude-models-may-be-20-30-more-expensive-than-gpt-in-enterprise-settings/",
    "published_iso": "2025-05-01T20:14:04Z",
    "summary": "<img alt=\"Credit: VentureBeat using DALL-E 3\" class=\"attachment-single-feed size-single-feed wp-post-image\" height=\"385\" src=\"https://venturebeat.com/wp-content/uploads/2025/05/ChatGPT-Image-May-1-2025-11_45_21-AM.png?w=578\" width=\"578\" /><hr />It is a well-known fact that different model families can use different tokenizers. However, there has been limited analysis on how the process of “tokenization” itself varies across these tokenizers. Do all tokenizers result in the same number of tokens for a given input text? If not, how different are the generated tokens? How significant are the&hellip;<a href=\"https://venturebeat.com/ai/hidden-costs-in-ai-deployment-why-claude-models-may-be-20-30-more-expensive-than-gpt-in-enterprise-settings/\" target=\"_blank\">Read More</a>",
    "source_feed": "https://venturebeat.com/category/ai/feed/",
    "scraped_at_iso": "2025-05-02T08:05:42Z"
}