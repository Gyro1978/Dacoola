{
    "id": "3a8ffeb2e1a6a923a51b324c39ee40e5e8f2dad4b3e3317853e924e1c3880b04",
    "title": "AI is pushing the limits of the physical world",
    "link": "https://www.technologyreview.com/2025/04/21/1114764/ai-artificial-intelligence-architecture-building/",
    "published_iso": "2025-04-21T10:00:00Z",
    "summary": "<p>Architecture often assumes a binary between built projects and theoretical ones. What physics allows in actual buildings, after all, is vastly different from what architects can imagine and design (often referred to as “paper architecture”). That imagination has long been supported and enabled by design technology, but the latest advancements in artificial intelligence have prompted a surge in the theoretical.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"ai-generated shapes\" class=\"wp-image-1115400\" height=\"1024\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Karl-Daubmann-up.png?w=768\" width=\"768\" /><figcaption class=\"wp-element-caption\"><strong>Karl Daubmann, College of Architecture and Design at Lawrence Technological University</strong><br />“Very often the new synthetic image that comes from a tool like Midjourney or Stable Diffusion feels new,” says Daubmann, “infused by each of the multiple tools but rarely completely derived from them.”</figcaption></figure>\n\n\n\n<p>“Transductions: Artificial Intelligence in Architectural Experimentation,” a recent exhibition at the Pratt Institute in Brooklyn, brought together works from over 30 practitioners exploring the experimental, generative, and collaborative potential of artificial intelligence to open up new areas of architectural inquiry—something they’ve been working on for a decade or more, since long before AI became mainstream. Architects and exhibition co-­curators Jason Vigneri-Beane, Olivia Vien, Stephen Slaughter, and Hart Marlow explain that the works in “Transductions” emerged out of feedback loops among architectural discourses, techniques, formats, and media that range from imagery, text, and animation to mixed-­reality media and fabrication. The aim isn’t to present projects that are going to break ground anytime soon; architects already know how to build things with the tools they have. Instead, the show attempts to capture this very early stage in architecture’s exploratory engagement with AI.</p>\n\n\n\n<p>Technology has long enabled architecture to push the limits of form and function. As early as 1963, Sketchpad, one of the first architectural software programs, allowed architects and designers to move and change objects on screen. Rapidly, traditional hand drawing gave way to an ever-expanding suite of programs—­Revit, SketchUp, and BIM, among many others—that helped create floor plans and sections, track buildings’ energy usage, enhance sustainable construction, and aid in following building codes, to name just a few uses.&nbsp;</p>\n\n\n\n<p>The architects exhibiting in “Trans­ductions” view newly evolving forms of AI “like a new tool rather than a profession-­ending development,” says Vigneri-Beane, despite what some of his peers fear about the technology. He adds, “I do appreciate that it’s a somewhat unnerving thing for people, [but] I feel a familiarity with the rhetoric.”</p>\n\n\n\n<p>After all, he says, AI doesn’t just <em>do</em> the job. “To get something interesting and worth saving in AI, an enormous amount of time is required,” he says. “My architectural vocabulary has gotten much more precise and my visual sense has gotten an incredible workout, exercising all these muscles which have atrophied a little bit.”</p>\n\n\n\n<p>Vien agrees: “I think these are extremely powerful tools for an architect and designer. Do I think it’s the entire future of architecture? No, but I think it’s a tool and a medium that can expand the long history of mediums and media that architects can use not just to represent their work but as a generator of ideas.”</p>\n\n\n\n<figure class=\"wp-block-image alignwide size-large\"><img alt=\"\" class=\"wp-image-1115414\" height=\"3000\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Matsys-Andrew-Kudless.jpg?w=2000\" width=\"3000\" /><figcaption class=\"wp-element-caption\"><strong>Andrew Kudless, Hines College of Architecture and Design</strong><br />This image, part of the Urban Resolution series, shows how the Stable Diffusion AI model “is unable to focus on constructing a realistic image and instead duplicates features that are prominent in the local latent space,” Kudless says.</figcaption></figure>\n\n\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1115409\" height=\"3000\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Jason-Vigneri-Beane-01.jpg?w=2000\" width=\"3000\" /></figure>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1115412\" height=\"3000\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Jason-Vigneri-Beane-03.jpg?w=2000\" width=\"3000\" /></figure>\n</div>\n\n\n\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1115410\" height=\"3000\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Jason-Vigneri-Beane-05.jpg?w=2000\" width=\"3000\" /></figure>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1115413\" height=\"3000\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Jason-Vigneri-Beane-02.jpg?w=2000\" width=\"3000\" /></figure>\n</div>\n</div>\n\n\n\n<p class=\"imageSet__caption\"><strong>Jason Vigneri-Beane, Pratt Institute </strong><br />“These images are from a larger series on cyborg ecologies that have to do with co-creating with machines to imagine [other] machines,” says Vigneri-Beane. “I might refer to these as cryptomegafauna—infrastructural robots operating at an architectural scale.”</p>\n\n\n\n\n<figure class=\"wp-block-image alignwide size-large\"><img alt=\"\" class=\"wp-image-1115417\" height=\"1024\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Martin-Summers.jpg?w=1024\" width=\"1024\" /><figcaption class=\"wp-element-caption\"><strong>Martin Summers, University of Kentucky College of Design</strong><br />“Most AI is racing to emulate reality,” says Summers. “I prefer to revel in the hallucinations and misinterpretations like glitches and the sublogic they reveal present in a mediated reality.”</figcaption></figure>\n\n\n\n<figure class=\"wp-block-image alignwide size-large\"><img alt=\"\" class=\"wp-image-1115416\" height=\"3000\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Jason-Lee.jpg?w=2000\" width=\"3000\" /><figcaption class=\"wp-element-caption\"><strong>Jason Lee, Pratt Institute</strong><br />Lee typically uses AI “to generate iterations or high-resolution sketches,” he says. “I am also using it to experiment with how much realism one can incorporate with more abstract representation methods.”</figcaption></figure>\n\n\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-2 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1115419\" height=\"3000\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Olivia-Vien-04.jpg?w=2000\" width=\"3000\" /></figure>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1115530\" height=\"3600\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Olivia-Vien-02.jpeg?w=2000\" width=\"3600\" /></figure>\n</div>\n\n\n\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1115418\" height=\"3000\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Olivia-Vien-03.jpg?w=2000\" width=\"3000\" /></figure>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-1115532\" height=\"3600\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Olivia-Vien-01.jpeg?w=2000\" width=\"3600\" /></figure>\n</div>\n</div>\n\n\n\n<p class=\"imageSet__caption\"><strong>Olivia Vien, Pratt Institute</strong><br />For the series<em> Imprinting Grounds</em>, Vien created images digitally and fed them into Midjourney. “It riffs on the ideas of damask textile patterns in a more digital realm,” she says.</p>\n\n\n\n\n<figure class=\"wp-block-image alignwide size-large\"><img alt=\"\" class=\"wp-image-1115420\" height=\"3600\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/04/Robert-Brackett-III-02-up.png?w=1500\" width=\"2700\" /><figcaption class=\"wp-element-caption\"><strong>Robert Lee Brackett III, Pratt Institute</strong><br />“While new software raises concerns about the absence of traditional tools like hand drawing and modeling, I view these technologies as collaborators rather than replacements,” Brackett says. </figcaption></figure>",
    "source_feed": "https://www.technologyreview.com/topic/artificial-intelligence/feed/",
    "scraped_at_iso": "2025-05-02T08:05:42Z"
}