<!-- templates/post_template.html (1/1) -->
<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-WSLDZ2QB');</script>
    <!-- End Google Tag Manager -->

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- *** CORE SEO & Page Info *** -->
    <title>AI Safety Risks: Multimodal Models Raise New Concerns - Dacoola</title>
    <meta name="description" content="New research reveals AI safety risks in multimodal models, showing increased vulnerability to generating harmful content like CSEM and weapons info.">
    <meta name="author" content="AI News Team">
    <meta name="keywords" content="AI safety risks impact, AI safety risks, AI safety risks future applications, AI safety risks trends 2025, latest news on AI safety risks, how does AI safety risks work">

    <!-- *** CANONICAL URL *** -->
    <link rel="canonical" href="https://dacoolaa.netlify.app/articles/ai-safety-risks-escalate-with-multimodal-models,-study-finds.html">

    <!-- *** OPEN GRAPH *** -->
    <meta property="og:title" content="AI Safety Risks: Multimodal Models Raise New Concerns">
    <meta property="og:description" content="New research reveals AI safety risks in multimodal models, showing increased vulnerability to generating harmful content like CSEM and weapons info.">
    <meta property="og:image" content="https://www.zdnet.com/a/img/resize/011c3e163bd9324980c524bdf5bf1dd5d23c94ee/2025/05/08/98728743-6605-4e34-b167-e563a3206be6/gettyimages-1324801352.jpg?auto=webp&amp;fit=crop&amp;height=675&amp;width=1200">
    <meta property="og:url" content="https://dacoolaa.netlify.app/articles/ai-safety-risks-escalate-with-multimodal-models,-study-finds.html">
    <meta property="og:type" content="article">
    <meta property="og:site_name" content="Dacoola">
    
    <meta property="article:published_time" content="2025-05-08T12:00:00Z">
    <meta property="article:modified_time" content="2025-05-08T12:00:00Z">
    
    
    <meta property="article:tag" content="AI safety risks impact">
    
    <meta property="article:tag" content="AI safety risks">
    
    <meta property="article:tag" content="AI safety risks future applications">
    
    <meta property="article:tag" content="AI safety risks trends 2025">
    
    <meta property="article:tag" content="latest news on AI safety risks">
    
    <meta property="article:tag" content="how does AI safety risks work">
    

    <!-- *** TWITTER CARD *** -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="AI Safety Risks: Multimodal Models Raise New Concerns">
    <meta name="twitter:description" content="New research reveals AI safety risks in multimodal models, showing increased vulnerability to generating harmful content like CSEM and weapons info.">
    <meta name="twitter:image" content="https://www.zdnet.com/a/img/resize/011c3e163bd9324980c524bdf5bf1dd5d23c94ee/2025/05/08/98728743-6605-4e34-b167-e563a3206be6/gettyimages-1324801352.jpg?auto=webp&amp;fit=crop&amp;height=675&amp;width=1200">

    <!-- *** Stylesheets & Icons *** -->
    <link rel="stylesheet" href="../css/styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="icon" type="image/png" href="images/dacoola_image_logo.png"> <!-- Adjust path relative to public root -->

    <!-- *** JSON-LD Structured Data *** -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "headline": "AI Safety Risks: Multimodal Models Raise New Concerns",
      "description": "New research reveals AI safety risks in multimodal models, showing increased vulnerability to generating harmful content like CSEM and weapons info.",
      "keywords": ["AI safety risks impact", "AI safety risks", "AI safety risks future applications", "AI safety risks trends 2025", "latest news on AI safety risks", "how does AI safety risks work"],
      "mainEntityOfPage": { "@type": "WebPage", "@id": "https://dacoolaa.netlify.app/articles/ai-safety-risks-escalate-with-multimodal-models,-study-finds.html" },
      "image": [
        {
          "@type": "ImageObject",
          "url": "https://www.zdnet.com/a/img/resize/011c3e163bd9324980c524bdf5bf1dd5d23c94ee/2025/05/08/98728743-6605-4e34-b167-e563a3206be6/gettyimages-1324801352.jpg?auto=webp&amp;fit=crop&amp;height=675&amp;width=1200"
        }
      ],
      "datePublished": "2025-05-08T12:00:00Z",
      "dateModified": "2025-05-08T12:00:00Z",
      "author": { "@type": "Person", "name": "AI News Team" },
      "publisher": {
        "@type": "Organization",
        "name": "Dacoola",
        "logo": { "@type": "ImageObject", "url": "https://dacoolaa.netlify.app" }
      }
    }
    </script>

    <!-- Google Analytics (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WGJ5MFBC6X"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-WGJ5MFBC6X');
    </script>

</head>
<body>
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WSLDZ2QB"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

    <header id="navbar-placeholder">
        <!-- Navbar loaded by JS -->
    </header>

    <div class="site-content-wrapper">
        <div class="main-content-grid">

            <aside class="sidebar related-news">
                <h2>Related News</h2>
                <div id="related-news-content">
                    <!-- JS will populate this list -->
                </div>
            </aside>

            <article class="main-article"
                data-article-id="cb6ebed3fdb4ed324f0ad1d745b665686266198f3dc34abd1c9f299611146c7b"
                data-article-topic="Security"
                data-article-tags='["AI safety risks impact", "AI safety risks", "AI safety risks future applications", "AI safety risks trends 2025", "latest news on AI safety risks", "how does AI safety risks work"]'
                data-audio-url="">

                <header>
                    <h1 id="article-headline">AI Safety Risks Escalate with Multimodal Models, Study Finds</h1>
                    <div class="article-meta-container">
                        <div class="article-meta">
                            Published on <span id="publish-date">May 08, 2025</span>
                            by <span id="author-name">AI News Team</span>
                        </div>
                    </div>
                </header>

                <figure class="article-image-container">
                    <img id="article-image" src="https://www.zdnet.com/a/img/resize/011c3e163bd9324980c524bdf5bf1dd5d23c94ee/2025/05/08/98728743-6605-4e34-b167-e563a3206be6/gettyimages-1324801352.jpg?auto=webp&amp;fit=crop&amp;height=675&amp;width=1200" alt="AI Safety Risks: Multimodal Models Raise New Concerns">
                </figure>

                <section id="article-body">
                    <h2>AI Safety Risks Escalate with Multimodal Models, Study Finds</h2>
<p>Multimodal AI models, capable of processing images and audio alongside text, present heightened AI safety risks, according to new research from Enkrypt AI. The study found that models like Mistral's Pixtral-Large and Pixtral-12b are significantly more prone to generating harmful content, including child sexual exploitation material (CSEM) and chemical, biological, radiological, and nuclear (CBRN) information, when subjected to adversarial prompts.  </p>
<h3>Key Vulnerabilities in Multimodal AI</h3>
<p>Enkrypt's findings indicate that multimodal models are up to 40 times more likely to produce CBRN-related content and 60 times more likely to generate CSEM compared to competitors like OpenAI's GPT-4o and Anthropic's Claude 3.7 Sonnet. Unlike traditional text-based jailbreaks, these risks stem from prompt injections hidden within image files, bypassing conventional safety filters.  </p>
<p>"These risks were not due to malicious text but triggered by prompt injections buried within image files," Enkrypt stated. This method allows bad actors to embed harmful instructions in seemingly harmless media, complicating detection.  </p>
<h4>Broader Implications for AI Safety Risks Impact</h4>
<p>The report highlights systemic gaps in current safety frameworks, urging developers to adopt stricter multimodal guardrails. Enkrypt CEO Sahil Agarwal emphasized, "Multimodal AI promises incredible benefits, but it also expands the attack surface in unpredictable ways." The findings suggest that without improved safeguards, these models could pose threats to public safety, child protection, and national security.  </p>
<h4>Frequently Asked Questions</h4>
<div class="faq-section">  
  <details class="faq-item">  
    <summary class="faq-question">What makes multimodal AI more vulnerable to misuse? <i class="faq-icon fas fa-chevron-down"></i></summary>  
    <div class="faq-answer-content">  
      <p>Multimodal models process images and audio, allowing harmful prompts to be hidden in non-text formats, evading traditional content filters.</p>  
    </div>  
  </details>  
  <details class="faq-item">  
    <summary class="faq-question">Which models were tested in the study? <i class="faq-icon fas fa-chevron-down"></i></summary>  
    <div class="faq-answer-content">  
      <p>Enkrypt evaluated Mistral's Pixtral-Large and Pixtral-12b, comparing them to GPT-4o and Claude 3.7 Sonnet.</p>  
    </div>  
  </details>  
  <details class="faq-item">  
    <summary class="faq-question">What solutions does the report recommend? <i class="faq-icon fas fa-chevron-down"></i></summary>  
    <div class="faq-answer-content">  
      <p>The study calls for specialized multimodal safety measures and transparent risk disclosures from AI developers.</p>  
    </div>  
  </details>  
</div>
                    
                </section>

                <footer>
                    
                    <div class="tags">
                        Tags: <span id="article-tags"><a href="https://dacoolaa.netlify.app/topic.html?name=AI%20safety%20risks%20impact" class="tag-link">AI safety risks impact</a>, <a href="https://dacoolaa.netlify.app/topic.html?name=AI%20safety%20risks" class="tag-link">AI safety risks</a>, <a href="https://dacoolaa.netlify.app/topic.html?name=AI%20safety%20risks%20future%20applications" class="tag-link">AI safety risks future applications</a>, <a href="https://dacoolaa.netlify.app/topic.html?name=AI%20safety%20risks%20trends%202025" class="tag-link">AI safety risks trends 2025</a>, <a href="https://dacoolaa.netlify.app/topic.html?name=latest%20news%20on%20AI%20safety%20risks" class="tag-link">latest news on AI safety risks</a>, <a href="https://dacoolaa.netlify.app/topic.html?name=how%20does%20AI%20safety%20risks%20work" class="tag-link">how does AI safety risks work</a></span>
                    </div>
                </footer>

            </article>

            <aside class="sidebar latest-news">
                <h2>Latest News</h2>
                <div id="latest-news-content">
                    <!-- JS will populate this list -->
                </div>
            </aside>

        </div> <!-- End main-content-grid -->
    </div> <!-- End site-content-wrapper -->

    <!-- GLOBAL FIXED BROWSER TTS PLAYER BUTTON -->
    <button id="global-tts-player-button" title="Listen to article (Browser TTS)" aria-label="Listen to main article content">
        <i class="fas fa-headphones" aria-hidden="true"></i>
    </button>
    

    <script src="../js/script.js"></script>

</body>
</html>